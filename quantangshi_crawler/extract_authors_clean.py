#!/usr/bin/env python3
"""
æå–å…¨å”è©©æ‰€æœ‰ä½œè€…è…³æœ¬ - æ¸…ç†ç‰ˆ
å¾ quantangshi_volumes æ–‡ä»¶å¤¾ä¸­çš„æ‰€æœ‰æ–‡ä»¶ä¸­æå–ä½œè€…ä¿¡æ¯
å»æ‰ä½œè€…åç¨±æœ«å°¾çš„"è‘—"å­—ï¼Œé‡æ–°è¨ˆç®—å»é‡å¾Œçš„ä½œè€…æ•¸
"""

import os
import re
from collections import Counter

def clean_author_name(author_name):
    """æ¸…ç†ä½œè€…åç¨±ï¼Œå»æ‰æœ«å°¾çš„"è‘—"å­—"""
    if author_name.endswith('è‘—'):
        return author_name[:-1]  # å»æ‰æœ€å¾Œä¸€å€‹å­—ç¬¦"è‘—"
    return author_name

def extract_authors_from_file(file_path):
    """å¾å–®å€‹æ–‡ä»¶ä¸­æå–ä½œè€…"""
    authors = []
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼åŒ¹é… "ä½œè€…: " å¾Œé¢çš„å…§å®¹
        author_pattern = r'ä½œè€…:\s*(.+?)(?:\n|$)'
        matches = re.findall(author_pattern, content)
        
        for match in matches:
            author = match.strip()
            if author and author != "æœªçŸ¥ä½œè€…":
                # æ¸…ç†ä½œè€…åç¨±
                clean_author = clean_author_name(author)
                authors.append(clean_author)
                
    except Exception as e:
        print(f"è®€å–æ–‡ä»¶ {file_path} æ™‚å‡ºéŒ¯: {e}")
    
    return authors

def extract_all_authors(volumes_dir):
    """å¾æ‰€æœ‰æ–‡ä»¶ä¸­æå–ä½œè€…"""
    all_authors = []
    file_count = 0
    
    if not os.path.exists(volumes_dir):
        print(f"ç›®éŒ„ä¸å­˜åœ¨: {volumes_dir}")
        return []
    
    # éæ­·ç›®éŒ„ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    for filename in os.listdir(volumes_dir):
        if filename.endswith('.txt') and filename.startswith('å…¨å”è©©_ç¬¬'):
            file_path = os.path.join(volumes_dir, filename)
            file_count += 1
            
            print(f"æ­£åœ¨è™•ç†: {filename}")
            authors = extract_authors_from_file(file_path)
            all_authors.extend(authors)
    
    print(f"\nç¸½å…±è™•ç†äº† {file_count} å€‹æ–‡ä»¶")
    return all_authors

def analyze_authors(authors_list):
    """åˆ†æä½œè€…çµ±è¨ˆä¿¡æ¯"""
    if not authors_list:
        print("æ²’æœ‰æ‰¾åˆ°ä»»ä½•ä½œè€…")
        return
    
    # çµ±è¨ˆæ¯å€‹ä½œè€…å‡ºç¾çš„æ¬¡æ•¸
    author_counts = Counter(authors_list)
    
    print(f"\nğŸ“Š ä½œè€…çµ±è¨ˆ (æ¸…ç†å¾Œ):")
    print(f"   ç¸½ä½œè€…æ•¸: {len(author_counts)}")
    print(f"   ç¸½è©©æ­Œæ•¸: {len(authors_list)}")
    
    # é¡¯ç¤ºå‡ºç¾æ¬¡æ•¸æœ€å¤šçš„ä½œè€…
    print(f"\nğŸ† å‡ºç¾æ¬¡æ•¸æœ€å¤šçš„ä½œè€… (å‰20å):")
    for author, count in author_counts.most_common(20):
        print(f"   {author}: {count} é¦–")
    
    # é¡¯ç¤ºåªå‡ºç¾ä¸€æ¬¡çš„ä½œè€…æ•¸é‡
    single_occurrence = sum(1 for count in author_counts.values() if count == 1)
    print(f"\nğŸ“ åªå‡ºç¾ä¸€æ¬¡çš„ä½œè€…: {single_occurrence} äºº")
    
    return author_counts

def save_authors_list(authors_list, output_file="authors_list_clean.txt"):
    """ä¿å­˜ä½œè€…åˆ—è¡¨åˆ°æ–‡ä»¶"""
    unique_authors = sorted(list(set(authors_list)))
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("å…¨å”è©©ä½œè€…åˆ—è¡¨ (æ¸…ç†ç‰ˆ)\n")
        f.write("=" * 50 + "\n\n")
        f.write(f"ç¸½è¨ˆ: {len(unique_authors)} ä½ä½œè€…\n")
        f.write("æ³¨æ„: å·²å»æ‰ä½œè€…åç¨±æœ«å°¾çš„'è‘—'å­—\n\n")
        
        for i, author in enumerate(unique_authors, 1):
            f.write(f"{i:4d}. {author}\n")
    
    print(f"\nğŸ’¾ ä½œè€…åˆ—è¡¨å·²ä¿å­˜åˆ°: {output_file}")
    return unique_authors

def compare_with_original():
    """æ¯”è¼ƒæ¸…ç†å‰å¾Œçš„å·®ç•°"""
    print("\nğŸ” æ¯”è¼ƒæ¸…ç†å‰å¾Œçš„å·®ç•°:")
    
    # è®€å–åŸå§‹ä½œè€…åˆ—è¡¨
    original_authors = []
    if os.path.exists("authors_python_list.py"):
        try:
            with open("authors_python_list.py", 'r', encoding='utf-8') as f:
                content = f.read()
                # æå–ä½œè€…åˆ—è¡¨
                import re
                pattern = r"'([^']+)'"
                original_authors = re.findall(pattern, content)
        except:
            print("ç„¡æ³•è®€å–åŸå§‹ä½œè€…åˆ—è¡¨")
    
    if original_authors:
        original_unique = set(original_authors)
        print(f"   åŸå§‹ä½œè€…æ•¸: {len(original_unique)}")
        
        # æ¸…ç†åŸå§‹ä½œè€…åç¨±
        cleaned_original = [clean_author_name(author) for author in original_authors]
        cleaned_unique = set(cleaned_original)
        print(f"   æ¸…ç†å¾Œä½œè€…æ•¸: {len(cleaned_unique)}")
        print(f"   æ¸›å°‘äº†: {len(original_unique) - len(cleaned_unique)} ä½é‡è¤‡ä½œè€…")

def main():
    """ä¸»å‡½æ•¸"""
    volumes_dir = "quantangshi_volumes"
    
    print("ğŸ” é–‹å§‹æå–å…¨å”è©©ä½œè€… (æ¸…ç†ç‰ˆ)...")
    print("=" * 50)
    
    # æå–æ‰€æœ‰ä½œè€…
    all_authors = extract_all_authors(volumes_dir)
    
    if not all_authors:
        print("âŒ æ²’æœ‰æ‰¾åˆ°ä»»ä½•ä½œè€…ä¿¡æ¯")
        return
    
    # åˆ†æä½œè€…çµ±è¨ˆ
    author_counts = analyze_authors(all_authors)
    
    # ä¿å­˜ä½œè€…åˆ—è¡¨
    unique_authors = save_authors_list(all_authors)
    
    # è¼¸å‡ºPythonåˆ—è¡¨æ ¼å¼
    print(f"\nğŸ“‹ Pythonåˆ—è¡¨æ ¼å¼ (å‰10ä½ä½œè€…):")
    print("authors_list_clean = [")
    for i, author in enumerate(unique_authors[:10]):
        print(f"    '{author}',")
    if len(unique_authors) > 10:
        print(f"    # ... é‚„æœ‰ {len(unique_authors) - 10} ä½ä½œè€…")
    print("]")
    
    # ä¿å­˜å®Œæ•´çš„Pythonåˆ—è¡¨
    with open("authors_python_list_clean.py", 'w', encoding='utf-8') as f:
        f.write("# å…¨å”è©©ä½œè€…åˆ—è¡¨ - æ¸…ç†ç‰ˆ (Pythonæ ¼å¼)\n")
        f.write("# æ³¨æ„: å·²å»æ‰ä½œè€…åç¨±æœ«å°¾çš„'è‘—'å­—\n")
        f.write("authors_list_clean = [\n")
        for author in unique_authors:
            f.write(f"    '{author}',\n")
        f.write("]\n\n")
        f.write(f"# ç¸½è¨ˆ: {len(unique_authors)} ä½ä½œè€…\n")
        f.write("# æ¸…ç†å‰å¯èƒ½æœ‰é‡è¤‡ï¼Œå¦‚'å²ç„'å’Œ'å²ç„è‘—'ç¾åœ¨çµ±ä¸€ç‚º'å²ç„'\n")
    
    print(f"\nğŸ’¾ Pythonåˆ—è¡¨å·²ä¿å­˜åˆ°: authors_python_list_clean.py")
    
    # é¡¯ç¤ºä¸€äº›æœ‰è¶£çš„çµ±è¨ˆ
    print(f"\nğŸ¯ æœ‰è¶£çµ±è¨ˆ:")
    print(f"   æœ€å¸¸è¦‹çš„ä½œè€…: {author_counts.most_common(1)[0][0]} ({author_counts.most_common(1)[0][1]} é¦–)")
    print(f"   å¹³å‡æ¯ä½ä½œè€…è©©æ­Œæ•¸: {len(all_authors) / len(author_counts):.1f} é¦–")
    
    # æ¯”è¼ƒæ¸…ç†å‰å¾Œçš„å·®ç•°
    compare_with_original()
    
    # é¡¯ç¤ºä¸€äº›é‡è¤‡çš„ä¾‹å­
    print(f"\nğŸ“ é‡è¤‡æ¸…ç†ç¤ºä¾‹:")
    examples = [
        ("ç™½å±…æ˜“è‘—", "ç™½å±…æ˜“"),
        ("æœç”«è‘—", "æœç”«"),
        ("æç™½è‘—", "æç™½"),
        ("å²ç„è‘—", "å²ç„"),
        ("ä½šå", "ä½šå")
    ]
    for original, cleaned in examples:
        print(f"   '{original}' â†’ '{cleaned}'")

if __name__ == "__main__":
    main() 