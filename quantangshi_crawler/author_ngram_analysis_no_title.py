#!/usr/bin/env python3
"""
å…¨å”è©©ä½œè€… N-gram åˆ†æå·¥å…· (ä¸åŒ…å«æ¨™é¡Œ)
å°æ¯å€‹è©©äººé€²è¡Œ1-gram, 2-gram, 4-gramçµ±è¨ˆï¼Œåªçµ±è¨ˆè©©æ­Œå…§å®¹ï¼Œä¸åŒ…å«æ¨™é¡Œ
"""

import os
import re
import json
import csv
from collections import Counter, defaultdict
from typing import Dict, List, Tuple
from datetime import datetime

class AuthorNgramAnalyzerNoTitle:
    def __init__(self, volumes_dir: str = "quantangshi_volumes"):
        self.volumes_dir = volumes_dir
        self.poems_data = []
        self.author_poems = defaultdict(list)
        self.author_ngram_stats = defaultdict(lambda: {
            '1gram': Counter(),
            '2gram': Counter(),
            '4gram': Counter()
        })
        
    def load_data(self):
        """è¼‰å…¥æ‰€æœ‰è©©æ­Œæ•¸æ“š"""
        print("ğŸ“š æ­£åœ¨è¼‰å…¥è©©æ­Œæ•¸æ“š...")
        
        for filename in os.listdir(self.volumes_dir):
            if filename.endswith('.txt') and filename.startswith('å…¨å”è©©_ç¬¬'):
                file_path = os.path.join(self.volumes_dir, filename)
                volume_data = self.parse_volume_file(file_path)
                self.poems_data.extend(volume_data)
        
        print(f"âœ… è¼‰å…¥å®Œæˆï¼ç¸½å…± {len(self.poems_data)} é¦–è©©æ­Œ")
        
    def parse_volume_file(self, file_path: str) -> List[Dict]:
        """è§£æå–®å€‹å·æ–‡ä»¶"""
        poems = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # æå–å·è™Ÿ
            volume_match = re.search(r'å…¨å”è©©_ç¬¬(\d+)å·', os.path.basename(file_path))
            volume_num = int(volume_match.group(1)) if volume_match else 0
            
            # åˆ†å‰²è©©æ­Œ
            poem_sections = content.split('------------------------------')
            
            for section in poem_sections:
                if not section.strip():
                    continue
                    
                lines = section.strip().split('\n')
                if len(lines) < 3:
                    continue
                
                # æå–æ¨™é¡Œ
                title_line = lines[0].strip()
                if title_line and not title_line.startswith('å…¨å”è©©'):
                    current_poem = {
                        'title': title_line,
                        'volume': volume_num,
                        'content': ''
                    }
                    
                    # æå–ä½œè€…
                    for line in lines[1:]:
                        if 'ä½œè€…:' in line:
                            author = line.split('ä½œè€…:')[1].strip()
                            current_poem['author'] = author
                            break
                    
                    # æå–å…§å®¹
                    content_started = False
                    for line in lines[1:]:
                        if 'å…§å®¹:' in line:
                            content_started = True
                            continue
                        if content_started:
                            current_poem['content'] += line + '\n'
                    
                    if current_poem.get('title') and current_poem.get('author'):
                        poems.append(current_poem)
                        
        except Exception as e:
            print(f"âš ï¸  è§£ææ–‡ä»¶ {file_path} æ™‚å‡ºéŒ¯: {e}")
            
        return poems
    
    def clean_author_name(self, author: str) -> str:
        """æ¸…ç†ä½œè€…åç¨±ï¼Œå»æ‰"è‘—"å­—"""
        if author.endswith('è‘—'):
            return author[:-1]
        return author
    
    def clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬ï¼Œåªä¿ç•™ä¸­æ–‡å­—ç¬¦"""
        # ç§»é™¤æ¨™é»ç¬¦è™Ÿã€æ•¸å­—ã€è‹±æ–‡ç­‰ï¼Œåªä¿ç•™ä¸­æ–‡å­—ç¬¦
        chinese_chars = re.findall(r'[\u4e00-\u9fff]', text)
        return ''.join(chinese_chars)
    
    def extract_ngrams(self, text: str, n: int) -> List[str]:
        """æå–n-gram"""
        if len(text) < n:
            return []
        
        ngrams = []
        for i in range(len(text) - n + 1):
            ngram = text[i:i+n]
            ngrams.append(ngram)
        
        return ngrams
    
    def organize_poems_by_author(self):
        """æŒ‰ä½œè€…çµ„ç¹”è©©æ­Œ"""
        print("ğŸ‘¥ æ­£åœ¨æŒ‰ä½œè€…çµ„ç¹”è©©æ­Œ...")
        
        for poem in self.poems_data:
            author = poem.get('author', 'ä½šå')
            clean_author = self.clean_author_name(author)
            self.author_poems[clean_author].append(poem)
        
        print(f"âœ… çµ„ç¹”å®Œæˆï¼ç¸½å…± {len(self.author_poems)} ä½ä½œè€…")
    
    def analyze_author_ngrams(self):
        """åˆ†ææ¯ä½ä½œè€…çš„n-gram"""
        print("ğŸ” æ­£åœ¨åˆ†æä½œè€…n-gramçµ±è¨ˆ (ä¸åŒ…å«æ¨™é¡Œ)...")
        
        total_authors = len(self.author_poems)
        processed_authors = 0
        
        for author, poems in self.author_poems.items():
            processed_authors += 1
            if processed_authors % 100 == 0:
                print(f"   é€²åº¦: {processed_authors}/{total_authors}")
            
            # åˆä½µè©²ä½œè€…æ‰€æœ‰è©©æ­Œçš„å…§å®¹ï¼ˆä¸åŒ…å«æ¨™é¡Œï¼‰
            all_content = ""
            for poem in poems:
                content = poem.get('content', '')
                cleaned_content = self.clean_text(content)
                all_content += cleaned_content
            
            if all_content:
                # æå–1-gram, 2-gram, 4-gram
                for n in [1, 2, 4]:
                    ngram_type = f'{n}gram'
                    ngrams = self.extract_ngrams(all_content, n)
                    self.author_ngram_stats[author][ngram_type].update(ngrams)
        
        print(f"âœ… åˆ†æå®Œæˆï¼")
    
    def save_author_ngram_csvs(self, output_dir: str = "analysis_result/analysis_results_no_title"):
        """ä¿å­˜æ¯ä½ä½œè€…çš„n-gram CSVæ–‡ä»¶"""
        print("ğŸ’¾ æ­£åœ¨ä¿å­˜ä½œè€…n-gram CSVæ–‡ä»¶...")
        
        # å‰µå»ºè¼¸å‡ºç›®éŒ„
        csv_dir = os.path.join(output_dir, "author_ngram_csvs")
        os.makedirs(csv_dir, exist_ok=True)
        
        total_authors = len(self.author_ngram_stats)
        processed_authors = 0
        
        for author, ngram_data in self.author_ngram_stats.items():
            processed_authors += 1
            if processed_authors % 100 == 0:
                print(f"   é€²åº¦: {processed_authors}/{total_authors}")
            
            # ç‚ºæ¯å€‹n-gramé¡å‹å‰µå»ºCSVæ–‡ä»¶
            for n in [1, 2, 4]:
                ngram_type = f'{n}gram'
                counter = ngram_data[ngram_type]
                
                if counter:
                    # å‰µå»ºCSVæ–‡ä»¶å
                    filename = f"{author}_{n}gram_è©é »çµ±è¨ˆ.csv"
                    filepath = os.path.join(csv_dir, filename)
                    
                    # å¯«å…¥CSVæ–‡ä»¶
                    with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:
                        writer = csv.writer(csvfile)
                        writer.writerow(['æ’å', 'è©å½™', 'å‡ºç¾æ¬¡æ•¸'])
                        
                        # æŒ‰å‡ºç¾æ¬¡æ•¸æ’åº
                        sorted_items = counter.most_common()
                        for rank, (ngram, count) in enumerate(sorted_items, 1):
                            writer.writerow([rank, ngram, count])
        
        print(f"âœ… CSVæ–‡ä»¶å·²ä¿å­˜åˆ°: {csv_dir}")
    
    def save_detailed_analysis(self, output_dir: str = "analysis_result/analysis_results_no_title"):
        """ä¿å­˜è©³ç´°åˆ†æçµæœ"""
        print("ğŸ’¾ æ­£åœ¨ä¿å­˜è©³ç´°åˆ†æçµæœ...")
        
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜è©³ç´°çš„JSONåˆ†æçµæœ
        detailed_results = {
            'metadata': {
                'total_authors': len(self.author_ngram_stats),
                'total_poems': len(self.poems_data),
                'generated_at': datetime.now().isoformat(),
                'note': 'ä¸åŒ…å«æ¨™é¡Œçš„n-gramåˆ†æ'
            },
            'author_statistics': {}
        }
        
        for author, ngram_data in self.author_ngram_stats.items():
            author_stats = {
                'poem_count': len(self.author_poems[author]),
                'ngram_counts': {}
            }
            
            for n in [1, 2, 4]:
                ngram_type = f'{n}gram'
                counter = ngram_data[ngram_type]
                author_stats['ngram_counts'][ngram_type] = {
                    'unique_count': len(counter),
                    'total_count': sum(counter.values()),
                    'top_ngrams': [
                        {'ngram': ngram, 'count': count} 
                        for ngram, count in counter.most_common(50)
                    ]
                }
            
            detailed_results['author_statistics'][author] = author_stats
        
        json_file = os.path.join(output_dir, "detailed_ngram_analysis_no_title.json")
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(detailed_results, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… è©³ç´°åˆ†æçµæœå·²ä¿å­˜åˆ°: {json_file}")
    
    def save_author_summary(self, output_dir: str = "analysis_result/analysis_results_no_title"):
        """ä¿å­˜ä½œè€…æ‘˜è¦çµ±è¨ˆ"""
        print("ğŸ’¾ æ­£åœ¨ä¿å­˜ä½œè€…æ‘˜è¦çµ±è¨ˆ...")
        
        os.makedirs(output_dir, exist_ok=True)
        
        summary_data = []
        for author, ngram_data in self.author_ngram_stats.items():
            poem_count = len(self.author_poems[author])
            
            # è¨ˆç®—ç¸½å­—ç¬¦æ•¸ï¼ˆä¸åŒ…å«æ¨™é¡Œï¼‰
            total_chars = 0
            for poem in self.author_poems[author]:
                content = poem.get('content', '')
                cleaned_content = self.clean_text(content)
                total_chars += len(cleaned_content)
            
            summary_data.append({
                'author': author,
                'poem_count': poem_count,
                'total_chars': total_chars,
                'avg_chars_per_poem': total_chars / poem_count if poem_count > 0 else 0,
                'unique_1gram': len(ngram_data['1gram']),
                'unique_2gram': len(ngram_data['2gram']),
                'unique_4gram': len(ngram_data['4gram']),
                'total_1gram': sum(ngram_data['1gram'].values()),
                'total_2gram': sum(ngram_data['2gram'].values()),
                'total_4gram': sum(ngram_data['4gram'].values())
            })
        
        # æŒ‰å­—ç¬¦æ•¸æ’åº
        summary_data.sort(key=lambda x: x['total_chars'], reverse=True)
        
        # ä¿å­˜ç‚ºCSV
        csv_file = os.path.join(output_dir, "author_summary_no_title.csv")
        with open(csv_file, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['author', 'poem_count', 'total_chars', 'avg_chars_per_poem', 
                         'unique_1gram', 'unique_2gram', 'unique_4gram',
                         'total_1gram', 'total_2gram', 'total_4gram']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(summary_data)
        
        print(f"âœ… ä½œè€…æ‘˜è¦çµ±è¨ˆå·²ä¿å­˜åˆ°: {csv_file}")
    
    def create_analysis_report(self, output_dir: str = "analysis_result/analysis_results_no_title"):
        """å‰µå»ºåˆ†æå ±å‘Š"""
        print("ğŸ“Š æ­£åœ¨å‰µå»ºåˆ†æå ±å‘Š...")
        
        os.makedirs(output_dir, exist_ok=True)
        
        total_authors = len(self.author_ngram_stats)
        total_poems = len(self.poems_data)
        
        # è¨ˆç®—ç¸½å­—ç¬¦æ•¸ï¼ˆä¸åŒ…å«æ¨™é¡Œï¼‰
        total_chars = 0
        for author_poems in self.author_poems.values():
            for poem in author_poems:
                content = poem.get('content', '')
                cleaned_content = self.clean_text(content)
                total_chars += len(cleaned_content)
        
        # çµ±è¨ˆn-gramç¸½æ•¸
        total_1gram = sum(len(stats['1gram']) for stats in self.author_ngram_stats.values())
        total_2gram = sum(len(stats['2gram']) for stats in self.author_ngram_stats.values())
        total_4gram = sum(len(stats['4gram']) for stats in self.author_ngram_stats.values())
        
        report_file = os.path.join(output_dir, "analysis_report_no_title.md")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# å…¨å”è©©ä½œè€… N-gram åˆ†æå ±å‘Š (ä¸åŒ…å«æ¨™é¡Œ)\n\n")
            f.write(f"ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## ç¸½é«”çµ±è¨ˆ\n\n")
            f.write(f"- ç¸½ä½œè€…æ•¸: {total_authors:,}\n")
            f.write(f"- ç¸½è©©æ­Œæ•¸: {total_poems:,}\n")
            f.write(f"- ç¸½å­—ç¬¦æ•¸: {total_chars:,} (ä¸åŒ…å«æ¨™é¡Œ)\n")
            f.write(f"- å¹³å‡æ¯é¦–è©©: {total_chars/total_poems:.1f} å­—ç¬¦\n\n")
            
            f.write("## N-gram çµ±è¨ˆ\n\n")
            f.write(f"- 1-gram ç¸½æ•¸: {total_1gram:,}\n")
            f.write(f"- 2-gram ç¸½æ•¸: {total_2gram:,}\n")
            f.write(f"- 4-gram ç¸½æ•¸: {total_4gram:,}\n\n")
            
            f.write("## æ–‡ä»¶èªªæ˜\n\n")
            f.write("- `author_ngram_csvs/`: æ¯ä½ä½œè€…çš„n-gram CSVæ–‡ä»¶\n")
            f.write("- `detailed_ngram_analysis_no_title.json`: è©³ç´°çš„JSONåˆ†æçµæœ\n")
            f.write("- `author_summary_no_title.csv`: ä½œè€…æ‘˜è¦çµ±è¨ˆ\n")
            f.write("- `analysis_report_no_title.md`: æœ¬å ±å‘Š\n\n")
            
            f.write("## æ³¨æ„äº‹é …\n\n")
            f.write("- æœ¬åˆ†æåªçµ±è¨ˆè©©æ­Œå…§å®¹ï¼Œä¸åŒ…å«æ¨™é¡Œ\n")
            f.write("- å·²æ¸…ç†ä½œè€…åç¨±ï¼Œå»æ‰æœ«å°¾çš„'è‘—'å­—\n")
            f.write("- åªä¿ç•™ä¸­æ–‡å­—ç¬¦ï¼Œç§»é™¤æ¨™é»ç¬¦è™Ÿå’Œæ•¸å­—\n")
        
        print(f"âœ… åˆ†æå ±å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    def print_summary(self):
        """æ‰“å°æ‘˜è¦ä¿¡æ¯"""
        print("\nğŸ“‹ N-gramåˆ†ææ‘˜è¦ (ä¸åŒ…å«æ¨™é¡Œ):")
        print("=" * 50)
        
        total_authors = len(self.author_ngram_stats)
        total_poems = len(self.poems_data)
        
        # è¨ˆç®—ç¸½å­—ç¬¦æ•¸ï¼ˆä¸åŒ…å«æ¨™é¡Œï¼‰
        total_chars = 0
        for author_poems in self.author_poems.values():
            for poem in author_poems:
                content = poem.get('content', '')
                cleaned_content = self.clean_text(content)
                total_chars += len(cleaned_content)
        
        print(f"ç¸½ä½œè€…æ•¸: {total_authors:,}")
        print(f"ç¸½è©©æ­Œæ•¸: {total_poems:,}")
        print(f"ç¸½å­—ç¬¦æ•¸: {total_chars:,} (ä¸åŒ…å«æ¨™é¡Œ)")
        print(f"å¹³å‡æ¯é¦–è©©: {total_chars/total_poems:.1f} å­—ç¬¦")
        
        # çµ±è¨ˆn-gramç¸½æ•¸
        total_1gram = sum(len(stats['1gram']) for stats in self.author_ngram_stats.values())
        total_2gram = sum(len(stats['2gram']) for stats in self.author_ngram_stats.values())
        total_4gram = sum(len(stats['4gram']) for stats in self.author_ngram_stats.values())
        
        print(f"\nN-gramçµ±è¨ˆ:")
        print(f"  1-gram ç¸½æ•¸: {total_1gram:,}")
        print(f"  2-gram ç¸½æ•¸: {total_2gram:,}")
        print(f"  4-gram ç¸½æ•¸: {total_4gram:,}")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ” å…¨å”è©©ä½œè€… N-gram åˆ†æå·¥å…· (ä¸åŒ…å«æ¨™é¡Œ)")
    print("=" * 50)
    
    analyzer = AuthorNgramAnalyzerNoTitle()
    
    # è¼‰å…¥æ•¸æ“š
    analyzer.load_data()
    
    # æŒ‰ä½œè€…çµ„ç¹”è©©æ­Œ
    analyzer.organize_poems_by_author()
    
    # åˆ†æn-gram
    analyzer.analyze_author_ngrams()
    
    # ä¿å­˜çµæœ
    output_dir = "analysis_result/analysis_results_no_title"
    analyzer.save_author_ngram_csvs(output_dir)
    analyzer.save_detailed_analysis(output_dir)
    analyzer.save_author_summary(output_dir)
    analyzer.create_analysis_report(output_dir)
    
    # æ‰“å°æ‘˜è¦
    analyzer.print_summary()
    
    print(f"\nğŸ‰ N-gramåˆ†æ (ä¸åŒ…å«æ¨™é¡Œ) å®Œæˆï¼")
    print(f"ğŸ“ çµæœä¿å­˜åœ¨: {output_dir}")

if __name__ == "__main__":
    main() 