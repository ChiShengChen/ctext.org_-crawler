#!/usr/bin/env python3
"""
å…¨å”è©©çˆ¬èŸ² v3.0 - æ”¹é€²ç‰ˆ
å°ˆé–€ç”¨æ–¼çˆ¬å– ctext.org ä¸Šçš„å…¨å”è©©å…§å®¹
å¢å¼·åæª¢æ¸¬æ©Ÿåˆ¶ï¼Œæ›´å¥½çš„éŒ¯èª¤è™•ç†å’Œé‡è©¦æ©Ÿåˆ¶
"""

import re
import time
import json
import html
import os
import sys
from pathlib import Path
from urllib import request, error
from typing import List, Dict, Optional, Tuple
import random
import socket

BASE_URL = "https://ctext.org/quantangshi"

class ImprovedQuantangshiCrawler:
    def __init__(self, config_file: str = "config.json", output_dir: str = None, delay: float = None):
        # è¼‰å…¥é…ç½®æ–‡ä»¶
        self.config = self.load_config(config_file)
        
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è¨­ç½®ï¼Œå¦‚æœæ²’æœ‰æä¾›åƒæ•¸çš„è©±
        self.output_dir = Path(output_dir or self.config.get('crawler_settings', {}).get('output_directory', 'quantangshi_volumes'))
        self.delay = delay or self.config.get('crawler_settings', {}).get('delay_seconds', 3.0)
        
        # æ”¹é€²çš„è«‹æ±‚é ­ï¼Œæ›´åƒçœŸå¯¦ç€è¦½å™¨
        self.user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        ]
        
        self.session_headers = {
            "User-Agent": random.choice(self.user_agents),
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
            "Accept-Language": "zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Sec-Fetch-User": "?1",
            "Cache-Control": "max-age=0"
        }
        
        # å‰µå»ºè¼¸å‡ºç›®éŒ„
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # çµ±è¨ˆä¿¡æ¯
        self.success_count = 0
        self.failed_volumes = []
        self.captcha_volumes = []
        self.retry_count = 0
        
        # é‡è©¦é…ç½®
        self.max_retries = 3
        self.retry_delay = 10  # é‡è©¦é–“éš”ï¼ˆç§’ï¼‰
        
    def load_config(self, config_file: str) -> Dict:
        """è¼‰å…¥é…ç½®æ–‡ä»¶"""
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"âš ï¸  é…ç½®æ–‡ä»¶ {config_file} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜èªè¨­ç½®")
            return {}
        except json.JSONDecodeError as e:
            print(f"âŒ é…ç½®æ–‡ä»¶æ ¼å¼éŒ¯èª¤: {e}")
            return {}
    
    def get_random_headers(self):
        """ç²å–éš¨æ©Ÿçš„è«‹æ±‚é ­"""
        headers = self.session_headers.copy()
        headers["User-Agent"] = random.choice(self.user_agents)
        return headers
    
    def smart_delay(self):
        """æ™ºèƒ½å»¶é²ï¼Œé¿å…è¢«æª¢æ¸¬"""
        # åŸºç¤å»¶é²
        base_delay = self.delay
        
        # éš¨æ©Ÿè®ŠåŒ–
        random_delay = random.uniform(0.5, 2.0)
        
        # æ ¹æ“šé‡è©¦æ¬¡æ•¸å¢åŠ å»¶é²
        retry_multiplier = 1 + (self.retry_count * 0.5)
        
        total_delay = (base_delay + random_delay) * retry_multiplier
        
        print(f"   ç­‰å¾… {total_delay:.1f} ç§’...")
        time.sleep(total_delay)
    
    def check_for_captcha(self, content: str) -> bool:
        """æª¢æŸ¥é é¢æ˜¯å¦åŒ…å«é©—è­‰ç¢¼"""
        captcha_indicators = [
            'é©—è­‰ç¢¼', 'captcha', 'verification', 'security check',
            'è«‹è¼¸å…¥é©—è­‰ç¢¼', 'è«‹å®Œæˆé©—è­‰', 'robot check', 'human verification',
            'cloudflare', 'security challenge'
        ]
        
        content_lower = content.lower()
        for indicator in captcha_indicators:
            if indicator.lower() in content_lower:
                return True
        return False
    
    def fetch_volume_with_retry(self, volume_num: int) -> Tuple[Optional[List[Dict]], str]:
        """å¸¶é‡è©¦æ©Ÿåˆ¶çš„å·ç²å–"""
        for attempt in range(self.max_retries + 1):
            self.retry_count = attempt
            
            if attempt > 0:
                print(f"   ç¬¬ {attempt} æ¬¡é‡è©¦...")
                self.smart_delay()
            
            poems, status = self.fetch_volume(volume_num)
            
            # å¦‚æœæˆåŠŸæˆ–é‡åˆ°é©—è­‰ç¢¼ï¼Œä¸å†é‡è©¦
            if status == "success" or status == "captcha":
                return poems, status
            
            # å¦‚æœæ˜¯403éŒ¯èª¤ï¼Œå¢åŠ æ›´é•·çš„å»¶é²
            if "http_error_403" in status:
                print(f"   é‡åˆ°403éŒ¯èª¤ï¼Œç­‰å¾…æ›´é•·æ™‚é–“...")
                time.sleep(self.retry_delay * (attempt + 1))
            
            # æœ€å¾Œä¸€æ¬¡å˜—è©¦
            if attempt == self.max_retries:
                print(f"   å·²é‡è©¦ {self.max_retries} æ¬¡ï¼Œæ”¾æ£„è©²å·")
                return None, f"max_retries_exceeded_{status}"
        
        return None, "unknown_error"
    
    def fetch_volume(self, volume_num: int) -> Tuple[Optional[List[Dict]], str]:
        """ç²å–æŒ‡å®šå·çš„å…§å®¹"""
        url = f"{BASE_URL}/{volume_num}/zh"
        print(f"æ­£åœ¨ç²å–ç¬¬ {volume_num} å·: {url}")
        
        try:
            # æ™ºèƒ½å»¶é²
            self.smart_delay()
            
            # ä½¿ç”¨éš¨æ©Ÿè«‹æ±‚é ­
            headers = self.get_random_headers()
            req = request.Request(url, headers=headers)
            
            # è¨­ç½®è¶…æ™‚
            with request.urlopen(req, timeout=30) as resp:
                # æª¢æŸ¥æ˜¯å¦ç‚ºå£“ç¸®å…§å®¹
                content_encoding = resp.headers.get('Content-Encoding', '').lower()
                
                if content_encoding == 'gzip':
                    import gzip
                    content = gzip.decompress(resp.read()).decode('utf-8', errors='ignore')
                elif content_encoding == 'deflate':
                    import zlib
                    content = zlib.decompress(resp.read()).decode('utf-8', errors='ignore')
                else:
                    content = resp.read().decode('utf-8', errors='ignore')
                
                # å…ˆé€²è¡ŒHTMLè§£ç¢¼
                content = html.unescape(content)
                
                # # èª¿è©¦ï¼šæª¢æŸ¥HTMLè§£ç¢¼æ˜¯å¦æˆåŠŸ
                # print(f"   HTMLè§£ç¢¼å¾ŒåŒ…å«'å…¨å”è©©': {'å…¨å”è©©' in content}")
                # print(f"   HTMLè§£ç¢¼å¾ŒåŒ…å«'å¸äº¬ç¯‡': {'å¸äº¬ç¯‡' in content}")
                # print(f"   HTMLè§£ç¢¼å¾ŒåŒ…å«'æä¸–æ°‘': {'æä¸–æ°‘' in content}")
                
                # æª¢æŸ¥æ˜¯å¦éœ€è¦é©—è­‰ç¢¼
                if self.check_for_captcha(content):
                    print(f"âš ï¸  ç¬¬ {volume_num} å·éœ€è¦é©—è­‰ç¢¼")
                    return None, "captcha"
                
                # æª¢æŸ¥æ˜¯å¦åŒ…å«è©©æ­Œå…§å®¹
                validation_config = self.config.get('content_validation', {})
                check_for_poetry = validation_config.get('check_for_poetry_content', True)
                
                if check_for_poetry:
                    required_keywords = validation_config.get('required_keywords', [
                        'å…¨å”è©©', 'quantangshi',  
                        '<h2>ã€Š<a', '<td class="ctext">', 'è©©'
                    ])
                    
                    has_poetry_content = any(keyword in content for keyword in required_keywords)
                    
                    if not has_poetry_content:
                        print(f"âš ï¸  ç¬¬ {volume_num} å·å¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„è©©æ­Œé é¢")
                        print(f"   é é¢å…§å®¹é•·åº¦: {len(content)}")
                        return None, "invalid_page"
                
                # æå–è©©æ­Œï¼ˆé€™è£¡éœ€è¦å¯¦ç¾extract_poems_from_pageæ–¹æ³•ï¼‰
                poems = self.extract_poems_from_page(content)
                
                if poems:
                    print(f"âœ… ç¬¬ {volume_num} å·æˆåŠŸæå– {len(poems)} é¦–è©©")
                    return poems, "success"
                else:
                    print(f"âš ï¸  ç¬¬ {volume_num} å·æœªæ‰¾åˆ°è©©æ­Œå…§å®¹")
                    return [], "no_poems"
                    
        except error.HTTPError as e:
            print(f"âŒ ç¬¬ {volume_num} å· HTTP éŒ¯èª¤: {e.code}")
            return None, f"http_error_{e.code}"
        except error.URLError as e:
            print(f"âŒ ç¬¬ {volume_num} å· URL éŒ¯èª¤: {e.reason}")
            return None, "url_error"
        except socket.timeout:
            print(f"âŒ ç¬¬ {volume_num} å·è«‹æ±‚è¶…æ™‚")
            return None, "timeout"
        except Exception as e:
            print(f"âŒ ç¬¬ {volume_num} å·ç²å–å¤±æ•—: {e}")
            return None, "unknown_error"
    
    def extract_poems_from_page(self, content: str) -> List[Dict]:
        """å¾ç¶²é å…§å®¹ä¸­æå–è©©æ­Œ"""
        try:
            from bs4 import BeautifulSoup
            soup = BeautifulSoup(content, 'html.parser')
            
            poems = []
            
            # æ–¹æ³•1: å¾ä½œè€…ä¿¡æ¯é–‹å§‹æå–ï¼ˆé©ç”¨æ–¼æœ‰ä½œè€…çš„è©©æ­Œï¼‰
            author_spans = soup.find_all('span', class_='etext opt')
            
            for author_span in author_spans:
                author_text = author_span.get_text().strip()
                if not author_text or author_text == "é›»å­åœ–æ›¸é¤¨":
                    continue
                    
                # æ‰¾åˆ°åŒ…å«ä½œè€…ä¿¡æ¯çš„table
                parent_table = author_span.find_parent('table')
                if not parent_table:
                    continue
                    
                # åœ¨tableä¸­å°‹æ‰¾H2æ¨™é¡Œ
                h2_elem = parent_table.find('h2')
                if not h2_elem:
                    continue
                    
                title_text = h2_elem.get_text().strip()
                if not title_text.startswith('ã€Š') or not title_text.endswith('ã€‹'):
                    continue
                    
                # æå–æ¨™é¡Œ
                title = title_text[1:-1]  # ç§»é™¤ã€Šã€‹
                
                # å°‹æ‰¾è©©æ­Œå…§å®¹
                content = ""
                # å°‹æ‰¾ä¸‹ä¸€å€‹è¡¨æ ¼ä¸­çš„è©©æ­Œå…§å®¹
                table = parent_table.find_next_sibling('table')
                if table:
                    content_cells = table.find_all('td', class_='ctext')
                    if content_cells:
                        content_parts = []
                        for cell in content_cells:
                            cell_text = cell.get_text().strip()
                            if cell_text and not cell_text.startswith('æ‰“é–‹å­—å…¸'):
                                content_parts.append(cell_text)
                        content = '\n'.join(content_parts)
                
                if title and content:
                    poems.append({
                        'title': title,
                        'author': author_text,
                        'content': content
                    })
            
            # æ–¹æ³•2: å¦‚æœæ²’æœ‰æ‰¾åˆ°æœ‰ä½œè€…çš„è©©æ­Œï¼Œå˜—è©¦æå–æ²’æœ‰ä½œè€…çš„è©©æ­Œï¼ˆå¦‚ç¥­ç¥€æ¨‚ç« ï¼‰
            if not poems:
                # å°‹æ‰¾æ‰€æœ‰H2æ¨™é¡Œ
                h2_elements = soup.find_all('h2')
                
                for h2_elem in h2_elements:
                    title_text = h2_elem.get_text().strip()
                    if not title_text.startswith('ã€Š') or not title_text.endswith('ã€‹'):
                        continue
                    
                    # æå–æ¨™é¡Œ
                    title = title_text[1:-1]  # ç§»é™¤ã€Šã€‹
                    
                    # å°‹æ‰¾è©©æ­Œå…§å®¹
                    content = ""
                    # å°‹æ‰¾ä¸‹ä¸€å€‹è¡¨æ ¼ä¸­çš„è©©æ­Œå…§å®¹
                    table = h2_elem.find_parent('table')
                    if table:
                        next_table = table.find_next_sibling('table')
                        if next_table:
                            content_cells = next_table.find_all('td', class_='ctext')
                            if content_cells:
                                content_parts = []
                                for cell in content_cells:
                                    cell_text = cell.get_text().strip()
                                    if cell_text and not cell_text.startswith('æ‰“é–‹å­—å…¸'):
                                        content_parts.append(cell_text)
                                content = '\n'.join(content_parts)
                    
                    if title and content:
                        poems.append({
                            'title': title,
                            'author': 'ä½šå',  # æ²’æœ‰ä½œè€…ä¿¡æ¯æ™‚ä½¿ç”¨ä½šå
                            'content': content
                        })
            
            return poems
            
        except ImportError:
            print("âš ï¸  BeautifulSoupæœªå®‰è£ï¼Œç„¡æ³•è§£æHTMLå…§å®¹")
            return []
        except Exception as e:
            print(f"âš ï¸  è§£æè©©æ­Œå…§å®¹æ™‚å‡ºéŒ¯: {e}")
            return []
    
    def save_volume_to_file(self, poems: List[Dict], volume_num: int):
        """ä¿å­˜å–®å·è©©æ­Œåˆ°æ–‡ä»¶"""
        filename = f"å…¨å”è©©_ç¬¬{volume_num:03d}å·.txt"
        filepath = self.output_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(f"å…¨å”è©© ç¬¬{volume_num}å·\n")
            f.write("=" * 50 + "\n\n")
            
            for i, poem in enumerate(poems, 1):
                f.write(f"{i}. {poem.get('title', 'æœªçŸ¥æ¨™é¡Œ')}\n")
                f.write(f"   ä½œè€…: {poem.get('author', 'æœªçŸ¥ä½œè€…')}\n")
                f.write(f"   å…§å®¹:\n{poem.get('content', 'ç„¡å…§å®¹')}\n")
                f.write("-" * 30 + "\n\n")
        
        print(f"ğŸ’¾ å·²ä¿å­˜ç¬¬ {volume_num} å·åˆ° {filepath}")
    
    def crawl_volumes(self, start_volume: int = 1, end_volume: int = 900):
        """çˆ¬å–æŒ‡å®šç¯„åœçš„å·"""
        print(f"é–‹å§‹çˆ¬å–å…¨å”è©© (ç¬¬ {start_volume} å·åˆ°ç¬¬ {end_volume} å·)")
        print(f"è¼¸å‡ºç›®éŒ„: {self.output_dir}")
        print(f"è«‹æ±‚å»¶é²: {self.delay} ç§’")
        print("=" * 60 + "\n")
        
        total_volumes = end_volume - start_volume + 1
        
        for i, volume_num in enumerate(range(start_volume, end_volume + 1), 1):
            progress = (i / total_volumes) * 100
            print(f"é€²åº¦: {i}/{total_volumes} ({progress:.1f}%)")
            
            poems, status = self.fetch_volume_with_retry(volume_num)
            
            if status == "success":
                self.success_count += 1
                self.save_volume_to_file(poems, volume_num)
            elif status == "captcha":
                self.captcha_volumes.append(volume_num)
            else:
                self.failed_volumes.append((volume_num, status))
            
            # æ¯10å·é¡¯ç¤ºä¸€æ¬¡çµ±è¨ˆ
            if i % 10 == 0:
                print(f"ğŸ“Š ç•¶å‰çµ±è¨ˆ: æˆåŠŸ {self.success_count}, å¤±æ•— {len(self.failed_volumes)}, é©—è­‰ç¢¼ {len(self.captcha_volumes)}")
                print()
        
        # æœ€çµ‚çµ±è¨ˆ
        print("=" * 60)
        print("ğŸ‰ çˆ¬å–å®Œæˆï¼")
        print(f"âœ… æˆåŠŸ: {self.success_count} å·")
        print(f"âŒ å¤±æ•—: {len(self.failed_volumes)} å·")
        print(f"âš ï¸  é©—è­‰ç¢¼: {len(self.captcha_volumes)} å·")
        
        if self.failed_volumes:
            print("\nå¤±æ•—çš„å·:")
            for volume, status in self.failed_volumes:
                print(f"  ç¬¬ {volume} å·: {status}")
        
        if self.captcha_volumes:
            print(f"\néœ€è¦é©—è­‰ç¢¼çš„å·: {self.captcha_volumes}")

def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description="å…¨å”è©©çˆ¬èŸ² v3.0")
    parser.add_argument("--start", type=int, default=1, help="é–‹å§‹å·è™Ÿ")
    parser.add_argument("--end", type=int, default=900, help="çµæŸå·è™Ÿ")
    parser.add_argument("--output", type=str, default="quantangshi_volumes", help="è¼¸å‡ºç›®éŒ„")
    parser.add_argument("--delay", type=float, default=3.0, help="è«‹æ±‚å»¶é²ï¼ˆç§’ï¼‰")
    parser.add_argument("--config", type=str, default="config.json", help="é…ç½®æ–‡ä»¶")
    
    args = parser.parse_args()
    
    # æª¢æŸ¥ç¯„åœ
    if args.end - args.start + 1 > 50:
        response = input(f"âš ï¸  è­¦å‘Š: æœ¬æ¬¡é‹è¡Œå°‡çˆ¬å– {args.end - args.start + 1} å·ï¼Œè¶…éé…ç½®çš„æœ€å¤§é™åˆ¶ 50\næ˜¯å¦ç¹¼çºŒ? (y/N): ")
        if response.lower() != 'y':
            print("å·²å–æ¶ˆ")
            return
    
    print("ğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"   é–‹å§‹å·è™Ÿ: {args.start}")
    print(f"   çµæŸå·è™Ÿ: {args.end}")
    print(f"   è¼¸å‡ºç›®éŒ„: {args.output}")
    print(f"   è«‹æ±‚å»¶é²: {args.delay} ç§’")
    print(f"   é…ç½®æ–‡ä»¶: {args.config}")
    
    crawler = ImprovedQuantangshiCrawler(
        config_file=args.config,
        output_dir=args.output,
        delay=args.delay
    )
    
    crawler.crawl_volumes(args.start, args.end)

if __name__ == "__main__":
    main() 