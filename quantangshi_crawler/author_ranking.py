#!/usr/bin/env python3
"""
å…¨å”è©©ä½œè€…ä½œå“æ•¸é‡å®Œæ•´æ’åº
ç”Ÿæˆæ‰€æœ‰ä½œè€…çš„è©©æ­Œæ•¸é‡æ’åºåˆ—è¡¨
"""

import os
import re
from collections import Counter
from typing import List, Tuple, Dict
import json
from datetime import datetime

class AuthorRankingAnalyzer:
    def __init__(self, volumes_dir: str = "quantangshi_volumes"):
        self.volumes_dir = volumes_dir
        self.poems_data = []
        self.author_counts = Counter()
        
    def load_data(self):
        """è¼‰å…¥æ‰€æœ‰è©©æ­Œæ•¸æ“š"""
        print("ğŸ“š æ­£åœ¨è¼‰å…¥è©©æ­Œæ•¸æ“š...")
        
        for filename in os.listdir(self.volumes_dir):
            if filename.endswith('.txt') and filename.startswith('å…¨å”è©©_ç¬¬'):
                file_path = os.path.join(self.volumes_dir, filename)
                volume_data = self.parse_volume_file(file_path)
                self.poems_data.extend(volume_data)
        
        print(f"âœ… è¼‰å…¥å®Œæˆï¼ç¸½å…± {len(self.poems_data)} é¦–è©©æ­Œ")
        
    def parse_volume_file(self, file_path: str) -> List[Dict]:
        """è§£æå–®å€‹å·æ–‡ä»¶"""
        poems = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # æå–å·è™Ÿ
            volume_match = re.search(r'å…¨å”è©©_ç¬¬(\d+)å·', os.path.basename(file_path))
            volume_num = int(volume_match.group(1)) if volume_match else 0
            
            # åˆ†å‰²è©©æ­Œ
            poem_sections = content.split('------------------------------')
            
            for section in poem_sections:
                if not section.strip():
                    continue
                    
                lines = section.strip().split('\n')
                if len(lines) < 3:
                    continue
                
                # æå–æ¨™é¡Œ
                title_line = lines[0].strip()
                if title_line and not title_line.startswith('å…¨å”è©©'):
                    current_poem = {
                        'title': title_line,
                        'volume': volume_num,
                        'content': ''
                    }
                    
                    # æå–ä½œè€…
                    for line in lines[1:]:
                        if 'ä½œè€…:' in line:
                            author = line.split('ä½œè€…:')[1].strip()
                            current_poem['author'] = author
                            break
                    
                    # æå–å…§å®¹
                    content_started = False
                    for line in lines[1:]:
                        if 'å…§å®¹:' in line:
                            content_started = True
                            continue
                        if content_started:
                            current_poem['content'] += line + '\n'
                    
                    if current_poem.get('title') and current_poem.get('author'):
                        poems.append(current_poem)
                        
        except Exception as e:
            print(f"âš ï¸  è§£ææ–‡ä»¶ {file_path} æ™‚å‡ºéŒ¯: {e}")
            
        return poems
    
    def analyze_authors(self):
        """åˆ†æä½œè€…çµ±è¨ˆ"""
        print("ğŸ‘¥ æ­£åœ¨åˆ†æä½œè€…çµ±è¨ˆ...")
        
        # çµ±è¨ˆæ¯å€‹ä½œè€…çš„è©©æ­Œæ•¸é‡
        for poem in self.poems_data:
            author = poem.get('author', 'ä½šå')
            self.author_counts[author] += 1
        
        print(f"âœ… åˆ†æå®Œæˆï¼ç¸½å…± {len(self.author_counts)} ä½ä½œè€…")
    
    def get_author_ranking(self) -> List[Tuple[str, int]]:
        """ç²å–ä½œè€…æ’å"""
        return self.author_counts.most_common()
    
    def save_ranking_txt(self, output_file: str = "author_ranking.txt"):
        """ä¿å­˜æ’åç‚ºæ–‡æœ¬æ ¼å¼"""
        print("ğŸ’¾ æ­£åœ¨ä¿å­˜ä½œè€…æ’å...")
        
        ranking = self.get_author_ranking()
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("å…¨å”è©©ä½œè€…ä½œå“æ•¸é‡å®Œæ•´æ’åº\n")
            f.write("=" * 50 + "\n")
            f.write(f"ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ç¸½è©©æ­Œæ•¸: {len(self.poems_data):,} é¦–\n")
            f.write(f"ç¸½ä½œè€…æ•¸: {len(self.author_counts):,} ä½\n\n")
            
            f.write("ğŸ“Š ä½œè€…æ’å (æŒ‰ä½œå“æ•¸é‡é™åº)\n")
            f.write("-" * 40 + "\n")
            
            for i, (author, count) in enumerate(ranking, 1):
                f.write(f"{i:4d}. {author}: {count:,} é¦–\n")
            
            f.write(f"\nğŸ“ˆ çµ±è¨ˆæ‘˜è¦:\n")
            f.write(f"   æœ€å¤šç”¢ä½œè€…: {ranking[0][0]} ({ranking[0][1]:,} é¦–)\n")
            f.write(f"   æœ€å°‘ç”¢ä½œè€…: {ranking[-1][0]} ({ranking[-1][1]:,} é¦–)\n")
            f.write(f"   å¹³å‡æ¯ä½ä½œè€…: {len(self.poems_data) / len(self.author_counts):.1f} é¦–\n")
            
            # çµ±è¨ˆä¸åŒç”¢é‡ç´šåˆ¥çš„ä½œè€…æ•¸é‡
            single_poem_authors = sum(1 for _, count in ranking if count == 1)
            multi_poem_authors = len(ranking) - single_poem_authors
            
            f.write(f"\nğŸ“‹ ç”¢é‡åˆ†å¸ƒ:\n")
            f.write(f"   åªå¯«ä¸€é¦–è©©çš„ä½œè€…: {single_poem_authors:,} ä½\n")
            f.write(f"   å¯«å¤šé¦–è©©çš„ä½œè€…: {multi_poem_authors:,} ä½\n")
            
            # çµ±è¨ˆå‰10åã€å‰50åã€å‰100åçš„ä½œè€…
            top_10_total = sum(count for _, count in ranking[:10])
            top_50_total = sum(count for _, count in ranking[:50])
            top_100_total = sum(count for _, count in ranking[:100])
            
            f.write(f"\nğŸ† é ‚ç´šä½œè€…çµ±è¨ˆ:\n")
            f.write(f"   å‰10åä½œè€…ç¸½è©©æ­Œæ•¸: {top_10_total:,} é¦– ({top_10_total/len(self.poems_data)*100:.1f}%)\n")
            f.write(f"   å‰50åä½œè€…ç¸½è©©æ­Œæ•¸: {top_50_total:,} é¦– ({top_50_total/len(self.poems_data)*100:.1f}%)\n")
            f.write(f"   å‰100åä½œè€…ç¸½è©©æ­Œæ•¸: {top_100_total:,} é¦– ({top_100_total/len(self.poems_data)*100:.1f}%)\n")
        
        print(f"âœ… æ’åå·²ä¿å­˜åˆ°: {output_file}")
    
    def save_ranking_json(self, output_file: str = "author_ranking.json"):
        """ä¿å­˜æ’åç‚ºJSONæ ¼å¼"""
        print("ğŸ’¾ æ­£åœ¨ä¿å­˜JSONæ ¼å¼æ’å...")
        
        ranking = self.get_author_ranking()
        
        data = {
            'metadata': {
                'total_poems': len(self.poems_data),
                'total_authors': len(self.author_counts),
                'generated_at': datetime.now().isoformat()
            },
            'ranking': [
                {
                    'rank': i,
                    'author': author,
                    'poem_count': count
                }
                for i, (author, count) in enumerate(ranking, 1)
            ],
            'statistics': {
                'top_author': ranking[0][0],
                'top_author_count': ranking[0][1],
                'avg_poems_per_author': len(self.poems_data) / len(self.author_counts),
                'single_poem_authors': sum(1 for _, count in ranking if count == 1)
            }
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… JSONæ’åå·²ä¿å­˜åˆ°: {output_file}")
    
    def save_top_authors(self, output_file: str = "top_authors.txt", top_n: int = 100):
        """ä¿å­˜å‰Nåä½œè€…"""
        print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜å‰{top_n}åä½œè€…...")
        
        ranking = self.get_author_ranking()[:top_n]
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(f"å…¨å”è©©å‰{top_n}åä½œè€…æ’å\n")
            f.write("=" * 40 + "\n")
            f.write(f"ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            for i, (author, count) in enumerate(ranking, 1):
                f.write(f"{i:3d}. {author}: {count:,} é¦–\n")
        
        print(f"âœ… å‰{top_n}åä½œè€…å·²ä¿å­˜åˆ°: {output_file}")
    
    def print_summary(self):
        """æ‰“å°æ‘˜è¦ä¿¡æ¯"""
        ranking = self.get_author_ranking()
        
        print("\nğŸ“‹ ä½œè€…æ’åæ‘˜è¦:")
        print("=" * 40)
        print(f"ç¸½è©©æ­Œæ•¸: {len(self.poems_data):,} é¦–")
        print(f"ç¸½ä½œè€…æ•¸: {len(self.author_counts):,} ä½")
        print(f"å¹³å‡æ¯ä½ä½œè€…: {len(self.poems_data) / len(self.author_counts):.1f} é¦–")
        
        print(f"\nğŸ† å‰20åä½œè€…:")
        for i, (author, count) in enumerate(ranking[:20], 1):
            print(f"   {i:2d}. {author}: {count:,} é¦–")
        
        # çµ±è¨ˆä¿¡æ¯
        single_poem_authors = sum(1 for _, count in ranking if count == 1)
        print(f"\nğŸ“Š çµ±è¨ˆä¿¡æ¯:")
        print(f"   åªå¯«ä¸€é¦–è©©çš„ä½œè€…: {single_poem_authors:,} ä½")
        print(f"   å¯«å¤šé¦–è©©çš„ä½œè€…: {len(ranking) - single_poem_authors:,} ä½")
        
        # å‰10åä½œè€…ç¸½è©©æ­Œæ•¸
        top_10_total = sum(count for _, count in ranking[:10])
        print(f"   å‰10åä½œè€…ç¸½è©©æ­Œæ•¸: {top_10_total:,} é¦– ({top_10_total/len(self.poems_data)*100:.1f}%)")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ‘¥ å…¨å”è©©ä½œè€…ä½œå“æ•¸é‡æ’åºå·¥å…·")
    print("=" * 40)
    
    analyzer = AuthorRankingAnalyzer()
    
    # è¼‰å…¥æ•¸æ“š
    analyzer.load_data()
    
    # åˆ†æä½œè€…
    analyzer.analyze_authors()
    
    # ä¿å­˜çµæœ
    analyzer.save_ranking_txt()
    analyzer.save_ranking_json()
    analyzer.save_top_authors("top_100_authors.txt", 100)
    analyzer.save_top_authors("top_50_authors.txt", 50)
    analyzer.save_top_authors("top_20_authors.txt", 20)
    
    # æ‰“å°æ‘˜è¦
    analyzer.print_summary()
    
    print("\nğŸ‰ ä½œè€…æ’åå®Œæˆï¼")
    print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print("   - author_ranking.txt (å®Œæ•´æ’å)")
    print("   - author_ranking.json (JSONæ ¼å¼)")
    print("   - top_100_authors.txt (å‰100å)")
    print("   - top_50_authors.txt (å‰50å)")
    print("   - top_20_authors.txt (å‰20å)")

if __name__ == "__main__":
    main() 