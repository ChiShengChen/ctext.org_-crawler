#!/usr/bin/env python3
"""
å…¨å”è©©ä½œè€…è©é »çµ±è¨ˆå·¥å…· (ä¸åŒ…å«æ¨™é¡Œ)
çµ±è¨ˆæ¯ä½è©©äººçš„è©é »ï¼Œåªè¨ˆç®—è©©æ­Œå…§å®¹ï¼Œä¸åŒ…å«æ¨™é¡Œ
"""

import os
import re
import json
from collections import Counter, defaultdict
from typing import Dict, List, Tuple
from datetime import datetime

class AuthorWordFrequencyAnalyzer:
    def __init__(self, volumes_dir: str = "quantangshi_volumes"):
        self.volumes_dir = volumes_dir
        self.poems_data = []
        self.author_word_counts = defaultdict(Counter)
        self.author_char_counts = defaultdict(int)
        self.author_poem_counts = Counter()
        
    def load_data(self):
        """è¼‰å…¥æ‰€æœ‰è©©æ­Œæ•¸æ“š"""
        print("ğŸ“š æ­£åœ¨è¼‰å…¥è©©æ­Œæ•¸æ“š...")
        
        for filename in os.listdir(self.volumes_dir):
            if filename.endswith('.txt') and filename.startswith('å…¨å”è©©_ç¬¬'):
                file_path = os.path.join(self.volumes_dir, filename)
                volume_data = self.parse_volume_file(file_path)
                self.poems_data.extend(volume_data)
        
        print(f"âœ… è¼‰å…¥å®Œæˆï¼ç¸½å…± {len(self.poems_data)} é¦–è©©æ­Œ")
        
    def parse_volume_file(self, file_path: str) -> List[Dict]:
        """è§£æå–®å€‹å·æ–‡ä»¶"""
        poems = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # æå–å·è™Ÿ
            volume_match = re.search(r'å…¨å”è©©_ç¬¬(\d+)å·', os.path.basename(file_path))
            volume_num = int(volume_match.group(1)) if volume_match else 0
            
            # åˆ†å‰²è©©æ­Œ
            poem_sections = content.split('------------------------------')
            
            for section in poem_sections:
                if not section.strip():
                    continue
                    
                lines = section.strip().split('\n')
                if len(lines) < 3:
                    continue
                
                # æå–æ¨™é¡Œ
                title_line = lines[0].strip()
                if title_line and not title_line.startswith('å…¨å”è©©'):
                    current_poem = {
                        'title': title_line,
                        'volume': volume_num,
                        'content': ''
                    }
                    
                    # æå–ä½œè€…
                    for line in lines[1:]:
                        if 'ä½œè€…:' in line:
                            author = line.split('ä½œè€…:')[1].strip()
                            current_poem['author'] = author
                            break
                    
                    # æå–å…§å®¹
                    content_started = False
                    for line in lines[1:]:
                        if 'å…§å®¹:' in line:
                            content_started = True
                            continue
                        if content_started:
                            current_poem['content'] += line + '\n'
                    
                    if current_poem.get('title') and current_poem.get('author'):
                        poems.append(current_poem)
                        
        except Exception as e:
            print(f"âš ï¸  è§£ææ–‡ä»¶ {file_path} æ™‚å‡ºéŒ¯: {e}")
            
        return poems
    
    def clean_author_name(self, author: str) -> str:
        """æ¸…ç†ä½œè€…åç¨±ï¼Œå»æ‰"è‘—"å­—"""
        if author.endswith('è‘—'):
            return author[:-1]
        return author
    
    def clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬ï¼Œåªä¿ç•™ä¸­æ–‡å­—ç¬¦"""
        # ç§»é™¤æ¨™é»ç¬¦è™Ÿã€æ•¸å­—ã€è‹±æ–‡ç­‰ï¼Œåªä¿ç•™ä¸­æ–‡å­—ç¬¦
        chinese_chars = re.findall(r'[\u4e00-\u9fff]', text)
        return ''.join(chinese_chars)
    
    def analyze_author_word_frequency(self):
        """åˆ†ææ¯ä½ä½œè€…çš„è©é »çµ±è¨ˆ (ä¸åŒ…å«æ¨™é¡Œ)"""
        print("ğŸ” æ­£åœ¨åˆ†æä½œè€…è©é »çµ±è¨ˆ (ä¸åŒ…å«æ¨™é¡Œ)...")
        
        for poem in self.poems_data:
            author = poem.get('author', 'ä½šå')
            clean_author = self.clean_author_name(author)
            content = poem.get('content', '')
            
            # åªçµ±è¨ˆè©©æ­Œå…§å®¹ï¼Œä¸åŒ…å«æ¨™é¡Œ
            cleaned_content = self.clean_text(content)
            
            if cleaned_content:
                # çµ±è¨ˆå­—ç¬¦é »ç‡
                for char in cleaned_content:
                    self.author_word_counts[clean_author][char] += 1
                
                # çµ±è¨ˆå­—ç¬¦ç¸½æ•¸
                self.author_char_counts[clean_author] += len(cleaned_content)
                self.author_poem_counts[clean_author] += 1
        
        print(f"âœ… åˆ†æå®Œæˆï¼")
        print(f"   ç¸½å­—ç¬¦æ•¸: {sum(self.author_char_counts.values()):,}")
        print(f"   ç¸½è©©æ­Œæ•¸: {sum(self.author_poem_counts.values()):,}")
        print(f"   ç¸½ä½œè€…æ•¸: {len(self.author_word_counts):,}")
    
    def get_author_ranking_by_chars(self) -> List[Tuple[str, int]]:
        """æŒ‰å­—ç¬¦æ•¸ç²å–ä½œè€…æ’å"""
        return sorted(self.author_char_counts.items(), key=lambda x: x[1], reverse=True)
    
    def save_author_char_ranking(self, output_file: str = "author_char_ranking_no_title.txt"):
        """ä¿å­˜ä½œè€…å­—ç¬¦æ•¸æ’å (ä¸åŒ…å«æ¨™é¡Œ)"""
        print("ğŸ’¾ æ­£åœ¨ä¿å­˜ä½œè€…å­—ç¬¦æ•¸æ’å (ä¸åŒ…å«æ¨™é¡Œ)...")
        
        ranking = self.get_author_ranking_by_chars()
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("å…¨å”è©©ä½œè€…å­—ç¬¦æ•¸æ’å (ä¸åŒ…å«æ¨™é¡Œ)\n")
            f.write("=" * 50 + "\n")
            f.write(f"ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("æ³¨æ„: åªçµ±è¨ˆè©©æ­Œå…§å®¹å­—ç¬¦ï¼Œä¸åŒ…å«æ¨™é¡Œ\n\n")
            
            f.write("ğŸ“Š ä½œè€…æ’å (æŒ‰å­—ç¬¦æ•¸é™åº)\n")
            f.write("-" * 40 + "\n")
            
            for i, (author, char_count) in enumerate(ranking, 1):
                poem_count = self.author_poem_counts[author]
                avg_chars = char_count / poem_count if poem_count > 0 else 0
                f.write(f"{i:4d}. {author}: {char_count:,} å­—ç¬¦ ({poem_count:,} é¦–è©©, å¹³å‡ {avg_chars:.1f} å­—ç¬¦/é¦–)\n")
        
        print(f"âœ… ä½œè€…å­—ç¬¦æ•¸æ’åå·²ä¿å­˜åˆ°: {output_file}")
    
    def save_author_word_frequency(self, output_file: str = "author_word_frequency_no_title.json"):
        """ä¿å­˜ä½œè€…è©é »çµ±è¨ˆç‚ºJSONæ ¼å¼"""
        print("ğŸ’¾ æ­£åœ¨ä¿å­˜ä½œè€…è©é »çµ±è¨ˆ (JSONæ ¼å¼)...")
        
        results = {
            'metadata': {
                'total_authors': len(self.author_word_counts),
                'total_chars': sum(self.author_char_counts.values()),
                'total_poems': sum(self.author_poem_counts.values()),
                'generated_at': datetime.now().isoformat(),
                'note': 'åªçµ±è¨ˆè©©æ­Œå…§å®¹å­—ç¬¦ï¼Œä¸åŒ…å«æ¨™é¡Œ'
            },
            'author_statistics': {},
            'top_authors_by_chars': []
        }
        
        # ä½œè€…çµ±è¨ˆ
        for author in self.author_word_counts:
            char_count = self.author_char_counts[author]
            poem_count = self.author_poem_counts[author]
            avg_chars = char_count / poem_count if poem_count > 0 else 0
            
            results['author_statistics'][author] = {
                'total_chars': char_count,
                'total_poems': poem_count,
                'avg_chars_per_poem': avg_chars,
                'top_words': [
                    {'word': word, 'count': count} 
                    for word, count in self.author_word_counts[author].most_common(50)
                ]
            }
        
        # æŒ‰å­—ç¬¦æ•¸æ’å
        char_ranking = self.get_author_ranking_by_chars()
        results['top_authors_by_chars'] = [
            {
                'author': author, 
                'char_count': char_count,
                'poem_count': self.author_poem_counts[author],
                'avg_chars': char_count / self.author_poem_counts[author] if self.author_poem_counts[author] > 0 else 0
            }
            for author, char_count in char_ranking[:100]  # å‰100å
        ]
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ä½œè€…è©é »çµ±è¨ˆå·²ä¿å­˜åˆ°: {output_file}")
    
    def print_summary(self):
        """æ‰“å°æ‘˜è¦ä¿¡æ¯"""
        char_ranking = self.get_author_ranking_by_chars()
        
        print("\nğŸ“‹ ä½œè€…è©é »çµ±è¨ˆæ‘˜è¦ (ä¸åŒ…å«æ¨™é¡Œ):")
        print("=" * 50)
        print(f"ç¸½å­—ç¬¦æ•¸: {sum(self.author_char_counts.values()):,}")
        print(f"ç¸½è©©æ­Œæ•¸: {sum(self.author_poem_counts.values()):,}")
        print(f"ç¸½ä½œè€…æ•¸: {len(self.author_word_counts):,}")
        print(f"å¹³å‡æ¯é¦–è©©: {sum(self.author_char_counts.values()) / sum(self.author_poem_counts.values()):.1f} å­—ç¬¦")
        
        print(f"\nğŸ† æŒ‰å­—ç¬¦æ•¸å‰10åä½œè€…:")
        for i, (author, char_count) in enumerate(char_ranking[:10], 1):
            poem_count = self.author_poem_counts[author]
            avg_chars = char_count / poem_count if poem_count > 0 else 0
            print(f"   {i:2d}. {author}: {char_count:,} å­—ç¬¦ ({poem_count:,} é¦–è©©, å¹³å‡ {avg_chars:.1f} å­—ç¬¦/é¦–)")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ” å…¨å”è©©ä½œè€…è©é »çµ±è¨ˆå·¥å…· (ä¸åŒ…å«æ¨™é¡Œ)")
    print("=" * 50)
    
    analyzer = AuthorWordFrequencyAnalyzer()
    
    # è¼‰å…¥æ•¸æ“š
    analyzer.load_data()
    
    # åˆ†æä½œè€…è©é »
    analyzer.analyze_author_word_frequency()
    
    # ä¿å­˜çµæœ
    analyzer.save_author_char_ranking()
    analyzer.save_author_word_frequency()
    
    # æ‰“å°æ‘˜è¦
    analyzer.print_summary()
    
    print("\nğŸ‰ ä½œè€…è©é »çµ±è¨ˆ (ä¸åŒ…å«æ¨™é¡Œ) å®Œæˆï¼")
    print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print("   - author_char_ranking_no_title.txt (ä½œè€…å­—ç¬¦æ•¸æ’å)")
    print("   - author_word_frequency_no_title.json (è©³ç´°è©é »çµ±è¨ˆ)")

if __name__ == "__main__":
    main() 