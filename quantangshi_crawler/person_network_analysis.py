#!/usr/bin/env python3
"""
å…¨å”è©©äººç‰©é—œä¿‚ç¶²è·¯åˆ†æå·¥å…·
æå–è©©ä¸­æåˆ°çš„äººç‰©ï¼Œä¸¦ç”Ÿæˆäººç‰©é—œä¿‚ç¶²è·¯åœ–
"""

import os
import re
import json
import csv
from collections import defaultdict, Counter
from typing import Dict, List, Tuple, Set
from datetime import datetime
import networkx as nx
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

# è¨­ç½®ä¸­æ–‡å­—é«”
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class PersonNetworkAnalyzer:
    def __init__(self, volumes_dir: str = "quantangshi_volumes"):
        self.volumes_dir = volumes_dir
        self.poems_data = []
        self.person_poems = defaultdict(list)  # äººç‰© -> è©©æ­Œåˆ—è¡¨
        self.poem_persons = defaultdict(set)   # è©©æ­Œ -> äººç‰©é›†åˆ
        self.person_mentions = Counter()       # äººç‰©æåŠæ¬¡æ•¸
        self.person_connections = defaultdict(Counter)  # äººç‰©é—œä¿‚ç¶²çµ¡
        
        # å¸¸è¦‹çš„äººç‰©ç¨±è¬‚å’Œåå­—æ¨¡å¼
        self.person_patterns = [
            # å¸¸è¦‹å§“æ°
            r'[æç‹å¼µåŠ‰é™³æ¥Šé»ƒè¶™å³å‘¨å¾å­«é¦¬æœ±èƒ¡éƒ­ä½•é«˜æ—ç¾…é„­æ¢è¬å®‹å”è¨±éŸ“é¦®é„§æ›¹å½­æ›¾è•­ç”°è‘£è¢æ½˜æ–¼è”£è”¡ä½™æœè‘‰ç¨‹è˜‡é­å‘‚ä¸ä»»æ²ˆå§šç›§å§œå´”é¾è­šé™¸æ±ªèŒƒé‡‘çŸ³å»–è³ˆå¤éŸ‹ä»˜æ–¹ç™½é„’å­Ÿç†Šç§¦é‚±æ±Ÿå°¹è–›é–†æ®µé›·ä¾¯é¾å²é™¶é»è³€é¡§æ¯›éƒé¾”é‚µè¬éŒ¢åš´è¦ƒæ­¦æˆ´è«å­”å‘æ¹¯]',
            # å¸¸è¦‹åå­—
            r'[ç™½ææœç‹å­ŸéŸ“æŸ³åŠ‰éŸ‹å…ƒå¼µè³ˆå§šè¨±æ¸¾ç¾…éš±çš®æ—¥ä¼‘é™¸é¾œè’™å¸ç©ºåœ–é„­ç©€å´”å¡—å³èéŸ“å“æœè€é¶´éŸ‹èŠé»ƒæ»”å¾å¤¤ç¿æ‰¿è´Šç‹è²ç™½å¼µè ™è¤šè¼‰é„­é¨å°šé¡é½Šå·±è²«ä¼‘çšç„¶éˆä¸€éˆæ¾ˆæ¸…æ±Ÿæ³•æŒ¯æ³•ç…§å»£å®£ç„¡å¯æ£²ç™½æ£²ä¸€è­·åœ‹æ–‡ç›Šå¯æ­¢æ­¸ä»ç„å¯¶å­è˜­é¸æ£²é³³]',
            # å®˜è·ç¨±è¬‚
            r'[ä¸ç›¸|å°šæ›¸|ä¾éƒ|å¾¡å²|å°‡è»|å¤ªå®ˆ|åˆºå²|ç¸£ä»¤|ä¸»ç°¿|å¸é¦¬|åƒè»|æ ¡å°‰|éƒ½å°‰|ä¸­éƒ|éƒä¸­|å“¡å¤–|åšå£«|å­¸å£«|ç¿°æ—|ä¾è¬›|ä¾è®€|å¤ªå¸«|å¤ªå‚…|å¤ªä¿|å°‘å¸«|å°‘å‚…|å°‘ä¿]',
            # è¦ªå±¬ç¨±è¬‚
            r'[çˆ¶|æ¯|å…„|å¼Ÿ|å§Š|å¦¹|å­|å¥³|å¤«|å¦»|ç¿|å§‘|èˆ…|å§¨|å”|ä¼¯|ä¾„|ç”¥|å­«|æ›¾å­«|ç„å­«]',
            # æœ‹å‹ç¨±è¬‚
            r'[å‹|æœ‹|æ•…|èˆŠ|åŒ|åƒš|å¸«|å¾’|ç”Ÿ|é–€|å®¢|è³“|ä¸»]',
            # å…¶ä»–ç¨±è¬‚
            r'[å›|å¿|å…¬|ä¾¯|ä¼¯|å­|ç”·|å£«|æ°‘|äºº|å®¢|ä¸»|è³“|å‹|æœ‹|æ•…|èˆŠ|åŒ|åƒš|å¸«|å¾’|ç”Ÿ|é–€]'
        ]
        
        # å¸¸è¦‹äººç‰©åå­—ï¼ˆå¾å…¨å”è©©ä¸­æå–çš„çŸ¥åäººç‰©ï¼‰
        self.known_persons = {
            # è©©äºº
            'æç™½', 'æœç”«', 'ç™½å±…æ˜“', 'ç‹ç¶­', 'å­Ÿæµ©ç„¶', 'éŸ“æ„ˆ', 'æŸ³å®—å…ƒ', 'åŠ‰ç¦¹éŒ«', 
            'éŸ‹æ‡‰ç‰©', 'å…ƒç¨¹', 'å¼µç±', 'è³ˆå³¶', 'å§šåˆ', 'è¨±æ¸¾', 'ç¾…éš±', 'çš®æ—¥ä¼‘', 
            'é™¸é¾œè’™', 'å¸ç©ºåœ–', 'é„­ç©€', 'å´”å¡—', 'å³è', 'éŸ“å“', 'æœè€é¶´', 'éŸ‹èŠ',
            'é»ƒæ»”', 'å¾å¤¤', 'ç¿æ‰¿è´Š', 'ç‹è²ç™½', 'å¼µè ™', 'è¤šè¼‰', 'é„­é¨', 'å°šé¡',
            'é½Šå·±', 'è²«ä¼‘', 'çšç„¶', 'éˆä¸€', 'éˆæ¾ˆ', 'æ¸…æ±Ÿ', 'æ³•æŒ¯', 'æ³•ç…§', 'å»£å®£',
            'ç„¡å¯', 'æ£²ç™½', 'æ£²ä¸€', 'è­·åœ‹', 'æ–‡ç›Š', 'å¯æ­¢', 'æ­¸ä»', 'ç„å¯¶', 'å­è˜­',
            'é¸æ£²é³³',
            
            # æ­·å²äººç‰©
            'å”ç„å®—', 'å”è‚…å®—', 'å”ä»£å®—', 'å”å¾·å®—', 'å”é †å®—', 'å”æ†²å®—', 'å”ç©†å®—',
            'å”æ•¬å®—', 'å”æ–‡å®—', 'å”æ­¦å®—', 'å”å®£å®—', 'å”æ‡¿å®—', 'å”åƒ–å®—', 'å”æ˜­å®—',
            'æ­¦å‰‡å¤©', 'æ¥Šè²´å¦ƒ', 'å®‰ç¥¿å±±', 'å²æ€æ˜', 'éƒ­å­å„€', 'æå…‰å¼¼', 'ææ³Œ',
            'æˆ¿ç„é½¡', 'æœå¦‚æ™¦', 'é­å¾µ', 'é•·å­«ç„¡å¿Œ', 'è¤šé‚è‰¯', 'ç‹„ä»å‚‘', 'å¼µæŸ¬ä¹‹',
            'å§šå´‡', 'å®‹ç’Ÿ', 'å¼µèªª', 'å¼µä¹é½¡', 'ææ—ç”«', 'æ¥Šåœ‹å¿ ', 'é«˜åŠ›å£«',
            
            # å…¶ä»–çŸ¥åäººç‰©
            'å­”å­', 'å­Ÿå­', 'èŠå­', 'è€å­', 'å±ˆåŸ', 'å¸é¦¬é·', 'ç­å›º', 'è”¡é‚•',
            'æ›¹æ“', 'æ›¹ä¸•', 'æ›¹æ¤', 'é˜®ç±', 'åµ‡åº·', 'é™¶æ·µæ˜', 'è¬éˆé‹', 'è¬æœ“',
            'åº¾ä¿¡', 'ç‹å‹ƒ', 'æ¥Šç‚¯', 'ç›§ç…§é„°', 'é§±è³“ç‹', 'é™³å­æ˜‚', 'è³€çŸ¥ç« ',
            'å¼µæ—­', 'æ‡·ç´ ', 'å³é“å­', 'é–»ç«‹æœ¬', 'éŸ“å¹¹', 'å¼µè±', 'å‘¨æ˜‰'
        }
        
    def load_data(self):
        """è¼‰å…¥æ‰€æœ‰è©©æ­Œæ•¸æ“š"""
        print("ğŸ“š æ­£åœ¨è¼‰å…¥è©©æ­Œæ•¸æ“š...")
        
        for filename in os.listdir(self.volumes_dir):
            if filename.endswith('.txt') and filename.startswith('å…¨å”è©©_ç¬¬'):
                file_path = os.path.join(self.volumes_dir, filename)
                volume_data = self.parse_volume_file(file_path)
                self.poems_data.extend(volume_data)
        
        print(f"âœ… è¼‰å…¥å®Œæˆï¼ç¸½å…± {len(self.poems_data)} é¦–è©©æ­Œ")
        
    def parse_volume_file(self, file_path: str) -> List[Dict]:
        """è§£æå–®å€‹å·æ–‡ä»¶"""
        poems = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # æå–å·è™Ÿ
            volume_match = re.search(r'å…¨å”è©©_ç¬¬(\d+)å·', os.path.basename(file_path))
            volume_num = int(volume_match.group(1)) if volume_match else 0
            
            # åˆ†å‰²è©©æ­Œ
            poem_sections = content.split('------------------------------')
            
            for section in poem_sections:
                if not section.strip():
                    continue
                    
                lines = section.strip().split('\n')
                if len(lines) < 3:
                    continue
                
                # æå–æ¨™é¡Œ
                title_line = lines[0].strip()
                if title_line and not title_line.startswith('å…¨å”è©©'):
                    current_poem = {
                        'title': title_line,
                        'volume': volume_num,
                        'content': ''
                    }
                    
                    # æå–ä½œè€…
                    for line in lines[1:]:
                        if 'ä½œè€…:' in line:
                            author = line.split('ä½œè€…:')[1].strip()
                            current_poem['author'] = author
                            break
                    
                    # æå–å…§å®¹
                    content_started = False
                    for line in lines[1:]:
                        if 'å…§å®¹:' in line:
                            content_started = True
                            continue
                        if content_started:
                            current_poem['content'] += line + '\n'
                    
                    if current_poem.get('title') and current_poem.get('author'):
                        poems.append(current_poem)
                        
        except Exception as e:
            print(f"âš ï¸  è§£ææ–‡ä»¶ {file_path} æ™‚å‡ºéŒ¯: {e}")
            
        return poems
    
    def clean_author_name(self, author: str) -> str:
        """æ¸…ç†ä½œè€…åç¨±ï¼Œå»æ‰"è‘—"å­—"""
        if author.endswith('è‘—'):
            return author[:-1]
        return author
    
    def extract_persons_from_text(self, text: str) -> Set[str]:
        """å¾æ–‡æœ¬ä¸­æå–äººç‰©"""
        persons = set()
        
        # 1. ç›´æ¥åŒ¹é…å·²çŸ¥äººç‰©åå­—
        for person in self.known_persons:
            if person in text:
                persons.add(person)
        
        # 2. ä½¿ç”¨æ­£å‰‡è¡¨é”å¼åŒ¹é…äººç‰©æ¨¡å¼
        for pattern in self.person_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                if len(match) >= 2:  # è‡³å°‘2å€‹å­—ç¬¦
                    persons.add(match)
        
        # 3. åŒ¹é…å¸¸è¦‹çš„äººç‰©ç¨±è¬‚æ¨¡å¼
        # å§“æ° + åå­—
        surname_pattern = r'([æç‹å¼µåŠ‰é™³æ¥Šé»ƒè¶™å³å‘¨å¾å­«é¦¬æœ±èƒ¡éƒ­ä½•é«˜æ—ç¾…é„­æ¢è¬å®‹å”è¨±éŸ“é¦®é„§æ›¹å½­æ›¾è•­ç”°è‘£è¢æ½˜æ–¼è”£è”¡ä½™æœè‘‰ç¨‹è˜‡é­å‘‚ä¸ä»»æ²ˆå§šç›§å§œå´”é¾è­šé™¸æ±ªèŒƒé‡‘çŸ³å»–è³ˆå¤éŸ‹ä»˜æ–¹ç™½é„’å­Ÿç†Šç§¦é‚±æ±Ÿå°¹è–›é–†æ®µé›·ä¾¯é¾å²é™¶é»è³€é¡§æ¯›éƒé¾”é‚µè¬éŒ¢åš´è¦ƒæ­¦æˆ´è«å­”å‘æ¹¯])([ç™½ææœç‹å­ŸéŸ“æŸ³åŠ‰éŸ‹å…ƒå¼µè³ˆå§šè¨±æ¸¾ç¾…éš±çš®æ—¥ä¼‘é™¸é¾œè’™å¸ç©ºåœ–é„­ç©€å´”å¡—å³èéŸ“å“æœè€é¶´éŸ‹èŠé»ƒæ»”å¾å¤¤ç¿æ‰¿è´Šç‹è²ç™½å¼µè ™è¤šè¼‰é„­é¨å°šé¡é½Šå·±è²«ä¼‘çšç„¶éˆä¸€éˆæ¾ˆæ¸…æ±Ÿæ³•æŒ¯æ³•ç…§å»£å®£ç„¡å¯æ£²ç™½æ£²ä¸€è­·åœ‹æ–‡ç›Šå¯æ­¢æ­¸ä»ç„å¯¶å­è˜­é¸æ£²é³³])'
        matches = re.findall(surname_pattern, text)
        for surname, name in matches:
            full_name = surname + name
            if len(full_name) >= 2:
                persons.add(full_name)
        
        # 4. åŒ¹é…å®˜è· + å§“æ°çš„æ¨¡å¼
        title_pattern = r'(ä¸ç›¸|å°šæ›¸|ä¾éƒ|å¾¡å²|å°‡è»|å¤ªå®ˆ|åˆºå²|ç¸£ä»¤|ä¸»ç°¿|å¸é¦¬|åƒè»|æ ¡å°‰|éƒ½å°‰|ä¸­éƒ|éƒä¸­|å“¡å¤–|åšå£«|å­¸å£«|ç¿°æ—|ä¾è¬›|ä¾è®€|å¤ªå¸«|å¤ªå‚…|å¤ªä¿|å°‘å¸«|å°‘å‚…|å°‘ä¿)([æç‹å¼µåŠ‰é™³æ¥Šé»ƒè¶™å³å‘¨å¾å­«é¦¬æœ±èƒ¡éƒ­ä½•é«˜æ—ç¾…é„­æ¢è¬å®‹å”è¨±éŸ“é¦®é„§æ›¹å½­æ›¾è•­ç”°è‘£è¢æ½˜æ–¼è”£è”¡ä½™æœè‘‰ç¨‹è˜‡é­å‘‚ä¸ä»»æ²ˆå§šç›§å§œå´”é¾è­šé™¸æ±ªèŒƒé‡‘çŸ³å»–è³ˆå¤éŸ‹ä»˜æ–¹ç™½é„’å­Ÿç†Šç§¦é‚±æ±Ÿå°¹è–›é–†æ®µé›·ä¾¯é¾å²é™¶é»è³€é¡§æ¯›éƒé¾”é‚µè¬éŒ¢åš´è¦ƒæ­¦æˆ´è«å­”å‘æ¹¯])'
        matches = re.findall(title_pattern, text)
        for title, surname in matches:
            persons.add(title + surname)
        
        return persons
    
    def analyze_person_mentions(self):
        """åˆ†æè©©ä¸­çš„äººç‰©æåŠ"""
        print("ğŸ” æ­£åœ¨åˆ†æè©©ä¸­çš„äººç‰©æåŠ...")
        
        total_poems_with_persons = 0
        
        for poem in self.poems_data:
            title = poem.get('title', '')
            content = poem.get('content', '')
            full_text = title + '\n' + content
            
            # æå–äººç‰©
            persons = self.extract_persons_from_text(full_text)
            
            if persons:
                total_poems_with_persons += 1
                poem_id = f"{poem.get('author', 'ä½šå')}_{poem.get('title', '')}"
                
                # è¨˜éŒ„è©©æ­Œä¸­çš„äººç‰©
                self.poem_persons[poem_id] = persons
                
                # çµ±è¨ˆäººç‰©æåŠæ¬¡æ•¸
                for person in persons:
                    self.person_mentions[person] += 1
                    self.person_poems[person].append(poem)
                
                # å»ºç«‹äººç‰©é—œä¿‚ç¶²çµ¡ï¼ˆåŒä¸€é¦–è©©ä¸­çš„äººç‰©ç›¸äº’é—œè¯ï¼‰
                person_list = list(persons)
                for i in range(len(person_list)):
                    for j in range(i + 1, len(person_list)):
                        person1, person2 = person_list[i], person_list[j]
                        self.person_connections[person1][person2] += 1
                        self.person_connections[person2][person1] += 1
        
        print(f"âœ… åˆ†æå®Œæˆï¼")
        print(f"   æåˆ°äººç‰©çš„è©©æ­Œ: {total_poems_with_persons:,} é¦–")
        print(f"   ç™¼ç¾çš„äººç‰©: {len(self.person_mentions):,} å€‹")
        print(f"   äººç‰©æåŠç¸½æ¬¡æ•¸: {sum(self.person_mentions.values()):,}")
    
    def save_person_poems(self, output_file: str = "analysis_result/person_poems.csv"):
        """ä¿å­˜æåˆ°äººç‰©çš„è©©æ­Œåˆ—è¡¨"""
        print("ğŸ’¾ æ­£åœ¨ä¿å­˜æåˆ°äººç‰©çš„è©©æ­Œåˆ—è¡¨...")
        
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['è©©æ­ŒID', 'ä½œè€…', 'æ¨™é¡Œ', 'äººç‰©', 'æåŠæ¬¡æ•¸']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            
            for poem_id, persons in self.poem_persons.items():
                author, title = poem_id.split('_', 1)
                for person in persons:
                    writer.writerow({
                        'è©©æ­ŒID': poem_id,
                        'ä½œè€…': author,
                        'æ¨™é¡Œ': title,
                        'äººç‰©': person,
                        'æåŠæ¬¡æ•¸': self.person_mentions[person]
                    })
        
        print(f"âœ… æåˆ°äººç‰©çš„è©©æ­Œåˆ—è¡¨å·²ä¿å­˜åˆ°: {output_file}")
    
    def save_person_statistics(self, output_file: str = "analysis_result/person_statistics.csv"):
        """ä¿å­˜äººç‰©çµ±è¨ˆæ•¸æ“š"""
        print("ğŸ’¾ æ­£åœ¨ä¿å­˜äººç‰©çµ±è¨ˆæ•¸æ“š...")
        
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        # æŒ‰æåŠæ¬¡æ•¸æ’åº
        sorted_persons = self.person_mentions.most_common()
        
        with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['æ’å', 'äººç‰©', 'æåŠæ¬¡æ•¸', 'ç›¸é—œè©©æ­Œæ•¸', 'é—œè¯äººç‰©æ•¸']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            
            for rank, (person, mentions) in enumerate(sorted_persons, 1):
                related_poems = len(self.person_poems[person])
                related_persons = len(self.person_connections[person])
                
                writer.writerow({
                    'æ’å': rank,
                    'äººç‰©': person,
                    'æåŠæ¬¡æ•¸': mentions,
                    'ç›¸é—œè©©æ­Œæ•¸': related_poems,
                    'é—œè¯äººç‰©æ•¸': related_persons
                })
        
        print(f"âœ… äººç‰©çµ±è¨ˆæ•¸æ“šå·²ä¿å­˜åˆ°: {output_file}")
    
    def create_person_network(self, min_mentions: int = 5, min_connections: int = 2):
        """å‰µå»ºäººç‰©é—œä¿‚ç¶²è·¯åœ–"""
        print("ğŸ•¸ï¸ æ­£åœ¨å‰µå»ºäººç‰©é—œä¿‚ç¶²è·¯åœ–...")
        
        # å‰µå»ºNetworkXåœ–
        G = nx.Graph()
        
        # éæ¿¾é‡è¦äººç‰©ï¼ˆæåŠæ¬¡æ•¸å’Œé—œè¯æ•¸é”åˆ°é–¾å€¼ï¼‰
        important_persons = []
        for person, mentions in self.person_mentions.items():
            if mentions >= min_mentions:
                connections = len(self.person_connections[person])
                if connections >= min_connections:
                    important_persons.append(person)
        
        print(f"   é‡è¦äººç‰©æ•¸é‡: {len(important_persons)}")
        
        # æ·»åŠ ç¯€é»
        for person in important_persons:
            mentions = self.person_mentions[person]
            G.add_node(person, weight=mentions, size=min(mentions/10 + 5, 30))
        
        # æ·»åŠ é‚Š
        for person1 in important_persons:
            for person2 in important_persons:
                if person1 < person2:  # é¿å…é‡è¤‡é‚Š
                    weight = self.person_connections[person1].get(person2, 0)
                    if weight > 0:
                        G.add_edge(person1, person2, weight=weight)
        
        print(f"   ç¯€é»æ•¸é‡: {G.number_of_nodes()}")
        print(f"   é‚Šæ•¸é‡: {G.number_of_edges()}")
        
        return G, important_persons
    
    def draw_network_graph(self, G, output_file: str = "analysis_result/person_network.png"):
        """ç¹ªè£½äººç‰©é—œä¿‚ç¶²è·¯åœ–"""
        print("ğŸ¨ æ­£åœ¨ç¹ªè£½äººç‰©é—œä¿‚ç¶²è·¯åœ–...")
        
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        # è¨­ç½®åœ–çš„å¤§å°
        plt.figure(figsize=(20, 16))
        
        # è¨ˆç®—ç¯€é»å¤§å°å’Œé¡è‰²
        node_sizes = [G.nodes[node]['size'] for node in G.nodes()]
        node_weights = [G.nodes[node]['weight'] for node in G.nodes()]
        
        # è¨ˆç®—é‚Šçš„å¯¬åº¦
        edge_weights = [G[u][v]['weight'] for u, v in G.edges()]
        edge_widths = [w/2 for w in edge_weights]
        
        # è¨ˆç®—ä½ˆå±€
        pos = nx.spring_layout(G, k=3, iterations=50, seed=42)
        
        # ç¹ªè£½ç¯€é»
        nx.draw_networkx_nodes(G, pos, 
                              node_size=node_sizes,
                              node_color=node_weights,
                              cmap=plt.cm.viridis,
                              alpha=0.8)
        
        # ç¹ªè£½é‚Š
        nx.draw_networkx_edges(G, pos,
                              width=edge_widths,
                              alpha=0.3,
                              edge_color='gray')
        
        # ç¹ªè£½æ¨™ç±¤ï¼ˆåªé¡¯ç¤ºé‡è¦ç¯€é»ï¼‰
        labels = {}
        for node in G.nodes():
            if G.nodes[node]['weight'] >= 20:  # åªé¡¯ç¤ºæåŠæ¬¡æ•¸>=20çš„äººç‰©
                labels[node] = node
        
        nx.draw_networkx_labels(G, pos, labels, font_size=8, font_family='SimHei')
        
        # æ·»åŠ æ¨™é¡Œå’Œèªªæ˜
        plt.title('å…¨å”è©©äººç‰©é—œä¿‚ç¶²è·¯åœ–\n(ç¯€é»å¤§å°è¡¨ç¤ºæåŠæ¬¡æ•¸ï¼Œé‚Šå¯¬åº¦è¡¨ç¤ºé—œè¯å¼·åº¦)', 
                 fontsize=16, fontfamily='SimHei', pad=20)
        
        plt.tight_layout()
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… äººç‰©é—œä¿‚ç¶²è·¯åœ–å·²ä¿å­˜åˆ°: {output_file}")
    
    def save_network_data(self, G, output_file: str = "analysis_result/person_network_data.json"):
        """ä¿å­˜ç¶²è·¯æ•¸æ“šç‚ºJSONæ ¼å¼"""
        print("ğŸ’¾ æ­£åœ¨ä¿å­˜ç¶²è·¯æ•¸æ“š...")
        
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        network_data = {
            'metadata': {
                'total_nodes': G.number_of_nodes(),
                'total_edges': G.number_of_edges(),
                'generated_at': datetime.now().isoformat()
            },
            'nodes': [],
            'edges': []
        }
        
        # ç¯€é»æ•¸æ“š
        for node in G.nodes():
            network_data['nodes'].append({
                'id': node,
                'weight': G.nodes[node]['weight'],
                'size': G.nodes[node]['size']
            })
        
        # é‚Šæ•¸æ“š
        for u, v in G.edges():
            network_data['edges'].append({
                'source': u,
                'target': v,
                'weight': G[u][v]['weight']
            })
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(network_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ç¶²è·¯æ•¸æ“šå·²ä¿å­˜åˆ°: {output_file}")
    
    def print_summary(self):
        """æ‰“å°æ‘˜è¦ä¿¡æ¯"""
        print("\nğŸ“‹ äººç‰©é—œä¿‚ç¶²è·¯åˆ†ææ‘˜è¦:")
        print("=" * 50)
        
        total_poems_with_persons = len(self.poem_persons)
        total_persons = len(self.person_mentions)
        total_mentions = sum(self.person_mentions.values())
        
        print(f"æåˆ°äººç‰©çš„è©©æ­Œ: {total_poems_with_persons:,} é¦–")
        print(f"ç™¼ç¾çš„äººç‰©: {total_persons:,} å€‹")
        print(f"äººç‰©æåŠç¸½æ¬¡æ•¸: {total_mentions:,}")
        
        print(f"\nğŸ† æåŠæ¬¡æ•¸æœ€å¤šçš„å‰10ä½äººç‰©:")
        for i, (person, mentions) in enumerate(self.person_mentions.most_common(10), 1):
            related_poems = len(self.person_poems[person])
            print(f"   {i:2d}. {person}: {mentions:,} æ¬¡æåŠ ({related_poems:,} é¦–è©©)")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ•¸ï¸ å…¨å”è©©äººç‰©é—œä¿‚ç¶²è·¯åˆ†æå·¥å…·")
    print("=" * 50)
    
    analyzer = PersonNetworkAnalyzer()
    
    # è¼‰å…¥æ•¸æ“š
    analyzer.load_data()
    
    # åˆ†æäººç‰©æåŠ
    analyzer.analyze_person_mentions()
    
    # ä¿å­˜çµæœ
    analyzer.save_person_poems()
    analyzer.save_person_statistics()
    
    # å‰µå»ºç¶²è·¯åœ–
    G, important_persons = analyzer.create_person_network(min_mentions=5, min_connections=2)
    
    # ç¹ªè£½ç¶²è·¯åœ–
    analyzer.draw_network_graph(G)
    
    # ä¿å­˜ç¶²è·¯æ•¸æ“š
    analyzer.save_network_data(G)
    
    # æ‰“å°æ‘˜è¦
    analyzer.print_summary()
    
    print("\nğŸ‰ äººç‰©é—œä¿‚ç¶²è·¯åˆ†æå®Œæˆï¼")
    print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print("   - person_poems.csv (æåˆ°äººç‰©çš„è©©æ­Œåˆ—è¡¨)")
    print("   - person_statistics.csv (äººç‰©çµ±è¨ˆæ•¸æ“š)")
    print("   - person_network.png (äººç‰©é—œä¿‚ç¶²è·¯åœ–)")
    print("   - person_network_data.json (ç¶²è·¯æ•¸æ“š)")

if __name__ == "__main__":
    main() 