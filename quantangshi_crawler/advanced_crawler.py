#!/usr/bin/env python3
"""
é«˜ç´šå…¨å”è©©çˆ¬èŸ² v4.0
åŒ…å«æ›´å…ˆé€²çš„åæª¢æ¸¬æ©Ÿåˆ¶
"""

import requests
import time
import random
import json
import os
import re
from typing import Dict, List, Optional, Tuple
import html
from bs4 import BeautifulSoup
import urllib3
from datetime import datetime, timedelta
import threading

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

BASE_URL = "https://ctext.org/quantangshi"

class AdvancedQuantangshiCrawler:
    def __init__(self, config_file: str = "advanced_config.json", output_dir: str = None, delay: float = None):
        # è¼‰å…¥é…ç½®æ–‡ä»¶
        self.config = self.load_config(config_file)
        
        # åŸºæœ¬è¨­ç½®
        self.output_dir = output_dir or self.config.get('crawler_settings', {}).get('output_directory', 'quantangshi_volumes')
        self.delay = delay or self.config.get('crawler_settings', {}).get('delay_seconds', 3.0)
        self.max_retries = self.config.get('crawler_settings', {}).get('max_retries', 5)
        self.retry_delay = self.config.get('crawler_settings', {}).get('retry_delay', 8.0)
        
        # å‰µå»ºè¼¸å‡ºç›®éŒ„
        os.makedirs(self.output_dir, exist_ok=True)
        
        # ç”¨æˆ¶ä»£ç†æ± 
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/120.0.0.0',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15'
        ]
        
        # æœƒè©±ç®¡ç†
        self.session_pool = []
        self.current_session_index = 0
        self.session_lock = threading.Lock()
        
        # åˆå§‹åŒ–æœƒè©±æ± 
        self.init_session_pool()
        
        # çµ±è¨ˆä¿¡æ¯
        self.success_count = 0
        self.failed_count = 0
        self.captcha_count = 0
        self.retry_count = 0
        
        # è«‹æ±‚æ­·å²
        self.request_history = []
        self.max_history_size = 100
        
        # å†·å»æ™‚é–“ç®¡ç†
        self.last_request_time = 0
        self.min_request_interval = 2.0
        
        print("ğŸš€ é«˜ç´šçˆ¬èŸ²åˆå§‹åŒ–å®Œæˆ")

    def load_config(self, config_file: str) -> Dict:
        """è¼‰å…¥é…ç½®æ–‡ä»¶"""
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"âš ï¸  é…ç½®æ–‡ä»¶ {config_file} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜èªé…ç½®")
            return self.get_default_config()
        except json.JSONDecodeError:
            print(f"âš ï¸  é…ç½®æ–‡ä»¶ {config_file} æ ¼å¼éŒ¯èª¤ï¼Œä½¿ç”¨é»˜èªé…ç½®")
            return self.get_default_config()

    def get_default_config(self) -> Dict:
        """ç²å–é»˜èªé…ç½®"""
        return {
            "crawler_settings": {
                "start_volume": 1,
                "end_volume": 900,
                "output_directory": "quantangshi_volumes",
                "delay_seconds": 3.0,
                "max_retries": 5,
                "retry_delay": 8.0,
                "max_requests_per_session": 10,
                "session_pool_size": 3
            },
            "session_management": {
                "session_timeout": 300,
                "rotate_user_agents": True,
                "use_proxy": False,
                "proxy_list": []
            },
            "content_validation": {
                "check_for_poetry_content": True,
                "required_keywords": [
                    "å…¨å”è©©", "quantangshi", "<h2>ã€Š<a", "<td class=\"ctext\">", "è©©"
                ]
            }
        }

    def init_session_pool(self):
        """åˆå§‹åŒ–æœƒè©±æ± """
        pool_size = self.config.get('crawler_settings', {}).get('session_pool_size', 3)
        
        for i in range(pool_size):
            session = requests.Session()
            session.verify = False
            
            # è¨­ç½®æœƒè©±ç´šåˆ¥çš„è«‹æ±‚é ­
            session.headers.update({
                'User-Agent': random.choice(self.user_agents),
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'DNT': '1',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'none',
                'Sec-Fetch-User': '?1',
                'Cache-Control': 'max-age=0'
            })
            
            self.session_pool.append({
                'session': session,
                'created_at': datetime.now(),
                'request_count': 0,
                'last_used': datetime.now()
            })
        
        print(f"ğŸ”„ å·²åˆå§‹åŒ– {pool_size} å€‹æœƒè©±")

    def get_session(self):
        """ç²å–æœƒè©±"""
        with self.session_lock:
            # é¸æ“‡ä½¿ç”¨æœ€å°‘çš„æœƒè©±
            session_info = min(self.session_pool, key=lambda x: x['request_count'])
            session_info['request_count'] += 1
            session_info['last_used'] = datetime.now()
            
            # å¦‚æœæœƒè©±ä½¿ç”¨éå¤šï¼Œé‡æ–°å‰µå»º
            if session_info['request_count'] >= self.config.get('crawler_settings', {}).get('max_requests_per_session', 10):
                self.recreate_session(session_info)
            
            return session_info['session']

    def recreate_session(self, session_info):
        """é‡æ–°å‰µå»ºæœƒè©±"""
        print("ğŸ”„ é‡æ–°å‰µå»ºæœƒè©±...")
        
        # é—œé–‰èˆŠæœƒè©±
        session_info['session'].close()
        
        # å‰µå»ºæ–°æœƒè©±
        new_session = requests.Session()
        new_session.verify = False
        
        # è¨­ç½®æ–°çš„è«‹æ±‚é ­
        new_session.headers.update({
            'User-Agent': random.choice(self.user_agents),
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Cache-Control': 'max-age=0'
        })
        
        # æ›´æ–°æœƒè©±ä¿¡æ¯
        session_info['session'] = new_session
        session_info['created_at'] = datetime.now()
        session_info['request_count'] = 0
        session_info['last_used'] = datetime.now()

    def smart_delay(self):
        """æ™ºèƒ½å»¶é²"""
        # ç¢ºä¿æœ€å°è«‹æ±‚é–“éš”
        time_since_last = time.time() - self.last_request_time
        if time_since_last < self.min_request_interval:
            sleep_time = self.min_request_interval - time_since_last
            time.sleep(sleep_time)
        
        # åŸºç¤å»¶é²
        base_delay = self.delay
        
        # éš¨æ©Ÿè®ŠåŒ–
        random_delay = random.uniform(1.5, 5.0)
        
        # æ ¹æ“šé‡è©¦æ¬¡æ•¸å¢åŠ å»¶é²
        retry_multiplier = min(1 + (self.retry_count * 0.3), 2.5)
        
        # æ·»åŠ é¡å¤–çš„éš¨æ©Ÿå»¶é²
        extra_delay = random.uniform(0, 3.0)
        
        total_delay = (base_delay + random_delay + extra_delay) * retry_multiplier
        
        print(f"   ç­‰å¾… {total_delay:.1f} ç§’...")
        time.sleep(total_delay)
        
        self.last_request_time = time.time()

    def get_advanced_headers(self):
        """ç²å–é«˜ç´šè«‹æ±‚é ­"""
        headers = {
            "User-Agent": random.choice(self.user_agents),
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
            "Accept-Language": random.choice([
                "zh-CN,zh;q=0.9,en;q=0.8",
                "zh-TW,zh;q=0.9,en;q=0.8", 
                "en-US,en;q=0.9,zh;q=0.8",
                "zh-HK,zh;q=0.9,en;q=0.8"
            ]),
            "Accept-Encoding": "gzip, deflate, br",
            "DNT": random.choice(["0", "1"]),
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Sec-Fetch-User": "?1",
            "Cache-Control": random.choice([
                "max-age=0",
                "no-cache",
                "no-store"
            ]),
            "Pragma": random.choice(["no-cache", ""]),
            "Referer": random.choice([
                "https://ctext.org/",
                "https://ctext.org/zh",
                "https://www.google.com/",
                "https://www.baidu.com/",
                "https://ctext.org/quantangshi/",
                ""
            ]),
            "Sec-Ch-Ua": '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
            "Sec-Ch-Ua-Mobile": "?0",
            "Sec-Ch-Ua-Platform": random.choice(['"Windows"', '"macOS"', '"Linux"'])
        }
        
        return headers

    def check_for_captcha(self, content: str) -> bool:
        """æª¢æŸ¥é é¢æ˜¯å¦åŒ…å«é©—è­‰ç¢¼"""
        captcha_indicators = [
            'é©—è­‰ç¢¼', 'captcha', 'verification', 'security check',
            'è«‹è¼¸å…¥é©—è­‰ç¢¼', 'è«‹å®Œæˆé©—è­‰', 'robot check', 'human verification',
            'cloudflare', 'security challenge', 'checking your browser',
            'please complete the security check', 'ddos protection'
        ]
        
        content_lower = content.lower()
        for indicator in captcha_indicators:
            if indicator.lower() in content_lower:
                return True
        return False

    def fetch_volume_with_retry(self, volume_num: int) -> Tuple[Optional[List[Dict]], str]:
        """å¸¶é‡è©¦æ©Ÿåˆ¶çš„å·ç²å–"""
        for attempt in range(self.max_retries + 1):
            self.retry_count = attempt
            
            if attempt > 0:
                print(f"   ç¬¬ {attempt} æ¬¡é‡è©¦...")
                self.smart_delay()
            
            poems, status = self.fetch_volume(volume_num)
            
            # å¦‚æœæˆåŠŸï¼Œç›´æ¥è¿”å›
            if status == "success":
                return poems, status
            
            # å¦‚æœé‡åˆ°é©—è­‰ç¢¼ï¼Œæ›´æ›æœƒè©±ä¸¦ç­‰å¾…
            if status == "captcha":
                print(f"âš ï¸  é‡åˆ°é©—è­‰ç¢¼ï¼Œæ›´æ›æœƒè©±...")
                self.rotate_sessions()
                time.sleep(random.uniform(8, 20))  # æ›´é•·çš„ç­‰å¾…æ™‚é–“
                if attempt < self.max_retries:
                    continue
                else:
                    self.captcha_count += 1
                    return None, "captcha"
            
            # å¦‚æœæ˜¯403éŒ¯èª¤ï¼Œæ›´æ›æœƒè©±
            if "http_error_403" in status:
                print(f"   é‡åˆ°403éŒ¯èª¤ï¼Œæ›´æ›æœƒè©±...")
                self.rotate_sessions()
                time.sleep(random.uniform(5, 15))
            
            # æœ€å¾Œä¸€æ¬¡å˜—è©¦
            if attempt == self.max_retries:
                print(f"   å·²é‡è©¦ {self.max_retries} æ¬¡ï¼Œæ”¾æ£„è©²å·")
                return None, f"max_retries_exceeded_{status}"
        
        return None, "unknown_error"

    def rotate_sessions(self):
        """è¼ªæ›æœƒè©±"""
        with self.session_lock:
            for session_info in self.session_pool:
                self.recreate_session(session_info)

    def fetch_volume(self, volume_num: int) -> Tuple[Optional[List[Dict]], str]:
        """ç²å–æŒ‡å®šå·çš„å…§å®¹"""
        url = f"{BASE_URL}/{volume_num}/zh"
        print(f"æ­£åœ¨ç²å–ç¬¬ {volume_num} å·: {url}")
        
        try:
            # æ™ºèƒ½å»¶é²
            self.smart_delay()
            
            # ç²å–æœƒè©±
            session = self.get_session()
            
            # ä½¿ç”¨æœƒè©±ç™¼é€è«‹æ±‚
            response = session.get(url, timeout=30, headers=self.get_advanced_headers())
            
            # æª¢æŸ¥éŸ¿æ‡‰ç‹€æ…‹
            if response.status_code == 403:
                return None, "http_error_403"
            elif response.status_code != 200:
                return None, f"http_error_{response.status_code}"
            
            # ç²å–å…§å®¹
            content = response.text
            
            # å…ˆé€²è¡ŒHTMLè§£ç¢¼
            content = html.unescape(content)
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦é©—è­‰ç¢¼
            if self.check_for_captcha(content):
                print(f"âš ï¸  ç¬¬ {volume_num} å·éœ€è¦é©—è­‰ç¢¼")
                return None, "captcha"
            
            # æª¢æŸ¥æ˜¯å¦åŒ…å«è©©æ­Œå…§å®¹
            validation_config = self.config.get('content_validation', {})
            check_for_poetry = validation_config.get('check_for_poetry_content', True)
            
            if check_for_poetry:
                required_keywords = validation_config.get('required_keywords', [
                    'å…¨å”è©©', 'quantangshi',  
                    '<h2>ã€Š<a', '<td class="ctext">', 'è©©'
                ])
                
                has_poetry_content = any(keyword in content for keyword in required_keywords)
                
                if not has_poetry_content:
                    print(f"âš ï¸  ç¬¬ {volume_num} å·å¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„è©©æ­Œé é¢")
                    print(f"   é é¢å…§å®¹é•·åº¦: {len(content)}")
                    return None, "invalid_page"
            
            # æå–è©©æ­Œ
            poems = self.extract_poems_from_page(content)
            
            if poems:
                print(f"âœ… ç¬¬ {volume_num} å·æˆåŠŸæå– {len(poems)} é¦–è©©")
                return poems, "success"
            else:
                print(f"âš ï¸  ç¬¬ {volume_num} å·æœªæ‰¾åˆ°è©©æ­Œå…§å®¹")
                return None, "no_poems_found"
                
        except requests.exceptions.Timeout:
            print(f"   è«‹æ±‚è¶…æ™‚")
            return None, "timeout"
        except requests.exceptions.ConnectionError:
            print(f"   é€£æ¥éŒ¯èª¤")
            return None, "connection_error"
        except Exception as e:
            print(f"   æœªçŸ¥éŒ¯èª¤: {str(e)}")
            return None, f"unknown_error_{str(e)}"

    def extract_poems_from_page(self, content: str) -> List[Dict]:
        """å¾ç¶²é å…§å®¹ä¸­æå–è©©æ­Œ"""
        poems = []
        
        try:
            # ä½¿ç”¨BeautifulSoupè§£æHTML
            soup = BeautifulSoup(content, 'html.parser')
            
            # æ‰¾åˆ°æ‰€æœ‰çš„è©©æ­Œè¡¨æ ¼
            poem_tables = soup.find_all('table', {'width': '100%'})
            
            for table in poem_tables:
                # æŸ¥æ‰¾æ¨™é¡Œ
                title_element = table.find('h2')
                if title_element:
                    title_link = title_element.find('a')
                    if title_link:
                        title = title_link.get_text(strip=True)
                    else:
                        title = title_element.get_text(strip=True)
                else:
                    continue
                
                # æŸ¥æ‰¾ä½œè€…
                author_element = table.find('span', {'class': 'author'})
                if author_element:
                    author = author_element.get_text(strip=True)
                else:
                    # å˜—è©¦å…¶ä»–æ–¹å¼æŸ¥æ‰¾ä½œè€…
                    author_span = table.find('span')
                    if author_span:
                        author = author_span.get_text(strip=True)
                    else:
                        author = 'ä½šå'
                
                # æŸ¥æ‰¾è©©æ­Œå…§å®¹
                content_element = table.find('td', {'class': 'ctext'})
                if content_element:
                    content = content_element.get_text(strip=True)
                else:
                    # å˜—è©¦å…¶ä»–æ–¹å¼æŸ¥æ‰¾å…§å®¹
                    content_div = table.find('div', {'id': re.compile(r'comm.*')})
                    if content_div:
                        content = content_div.get_text(strip=True)
                    else:
                        content = ''
                
                # æ¸…ç†å…§å®¹
                if content:
                    content = re.sub(r'\s+', ' ', content).strip()
                    
                    if title and content:
                        poems.append({
                            'title': title,
                            'author': author,
                            'content': content
                        })
            
            return poems
            
        except ImportError:
            print("âš ï¸  BeautifulSoupæœªå®‰è£ï¼Œç„¡æ³•è§£æHTMLå…§å®¹")
            return []
        except Exception as e:
            print(f"âš ï¸  è§£æè©©æ­Œå…§å®¹æ™‚å‡ºéŒ¯: {e}")
            return []

    def save_volume_to_file(self, poems: List[Dict], volume_num: int):
        """ä¿å­˜å–®å·è©©æ­Œåˆ°æ–‡ä»¶"""
        filename = f"å…¨å”è©©_ç¬¬{volume_num:03d}å·.txt"
        filepath = os.path.join(self.output_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(f"å…¨å”è©© ç¬¬{volume_num}å·\n")
            f.write("=" * 50 + "\n\n")
            
            for i, poem in enumerate(poems, 1):
                f.write(f"{i}. {poem.get('title', 'æœªçŸ¥æ¨™é¡Œ')}\n")
                f.write(f"   ä½œè€…: {poem.get('author', 'æœªçŸ¥ä½œè€…')}\n")
                f.write(f"   å…§å®¹:\n{poem.get('content', 'ç„¡å…§å®¹')}\n")
                f.write("-" * 30 + "\n\n")
        
        print(f"ğŸ’¾ å·²ä¿å­˜ç¬¬ {volume_num} å·åˆ° {filepath}")

    def crawl_volumes(self, start_volume: int = 1, end_volume: int = 900):
        """çˆ¬å–æŒ‡å®šç¯„åœçš„å·"""
        print(f"é–‹å§‹çˆ¬å–å…¨å”è©© (ç¬¬ {start_volume} å·åˆ°ç¬¬ {end_volume} å·)")
        print(f"è¼¸å‡ºç›®éŒ„: {self.output_dir}")
        print(f"è«‹æ±‚å»¶é²: {self.delay} ç§’")
        print("=" * 60 + "\n")
        
        total_volumes = end_volume - start_volume + 1
        
        for i, volume_num in enumerate(range(start_volume, end_volume + 1), 1):
            progress = (i / total_volumes) * 100
            print(f"é€²åº¦: {i}/{total_volumes} ({progress:.1f}%)")
            
            poems, status = self.fetch_volume_with_retry(volume_num)
            
            if status == "success":
                self.success_count += 1
                self.save_volume_to_file(poems, volume_num)
            elif status == "captcha":
                self.captcha_count += 1
            else:
                self.failed_count += 1
            
            # æ¯10å·é¡¯ç¤ºä¸€æ¬¡çµ±è¨ˆ
            if i % 10 == 0:
                print(f"ğŸ“Š ç•¶å‰çµ±è¨ˆ: æˆåŠŸ {self.success_count}, å¤±æ•— {self.failed_count}, é©—è­‰ç¢¼ {self.captcha_count}")
                print()
        
        # æœ€çµ‚çµ±è¨ˆ
        print("=" * 60)
        print("ğŸ‰ çˆ¬å–å®Œæˆï¼")
        print(f"âœ… æˆåŠŸ: {self.success_count} å·")
        print(f"âŒ å¤±æ•—: {self.failed_count} å·")
        print(f"âš ï¸  é©—è­‰ç¢¼: {self.captcha_count} å·")
        
        if self.failed_count > 0:
            print(f"\nå¤±æ•—çš„å·: {self.failed_count} å·")
        
        if self.captcha_count > 0:
            print(f"\néœ€è¦é©—è­‰ç¢¼çš„å·: {self.captcha_count} å·")

def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description="é«˜ç´šå…¨å”è©©çˆ¬èŸ² v4.0")
    parser.add_argument("--start", type=int, default=1, help="é–‹å§‹å·è™Ÿ")
    parser.add_argument("--end", type=int, default=900, help="çµæŸå·è™Ÿ")
    parser.add_argument("--output", type=str, default="quantangshi_volumes", help="è¼¸å‡ºç›®éŒ„")
    parser.add_argument("--delay", type=float, default=3.0, help="è«‹æ±‚å»¶é²ï¼ˆç§’ï¼‰")
    parser.add_argument("--config", type=str, default="advanced_config.json", help="é…ç½®æ–‡ä»¶")
    
    args = parser.parse_args()
    
    # æª¢æŸ¥ç¯„åœ
    if args.end - args.start + 1 > 50:
        response = input(f"âš ï¸  è­¦å‘Š: æœ¬æ¬¡é‹è¡Œå°‡çˆ¬å– {args.end - args.start + 1} å·ï¼Œè¶…éé…ç½®çš„æœ€å¤§é™åˆ¶ 50\næ˜¯å¦ç¹¼çºŒ? (y/N): ")
        if response.lower() != 'y':
            print("å·²å–æ¶ˆ")
            return
    
    print("ğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"   é–‹å§‹å·è™Ÿ: {args.start}")
    print(f"   çµæŸå·è™Ÿ: {args.end}")
    print(f"   è¼¸å‡ºç›®éŒ„: {args.output}")
    print(f"   è«‹æ±‚å»¶é²: {args.delay} ç§’")
    print(f"   é…ç½®æ–‡ä»¶: {args.config}")
    
    # å‰µå»ºçˆ¬èŸ²å¯¦ä¾‹
    crawler = AdvancedQuantangshiCrawler(
        config_file=args.config,
        output_dir=args.output,
        delay=args.delay
    )
    
    # é–‹å§‹çˆ¬å–
    crawler.crawl_volumes(args.start, args.end)

if __name__ == "__main__":
    main() 